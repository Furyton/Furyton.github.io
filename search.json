[
  {
    "objectID": "diary/daily-reading/2024-03-10.html",
    "href": "diary/daily-reading/2024-03-10.html",
    "title": "GeLore",
    "section": "",
    "text": "Zhao, J., Zhang, Z., Chen, B., Wang, Z., Anandkumar, A., Tian, Y., 2024. GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection. https://doi.org/10.48550/arXiv.2403.03507\n\nA certain type of gradient update forms, i.e., \\[\nG_t=A-BW_{t-1}C, W_t=W_{t-1}-\\eta G_{t-1},\n\\]\nwhere \\(A\\) is a constant matrix, and \\(B,C\\) are projection, leads to low-rank with high probability \\(\\mathrm{rank}(G_t)\\rightarrow 1\\).\nMany neural nets with certain loss fuctions have this type of gradient update, and this work is to directly construct a low-rank gradient update that first projects the gradient into low dim space and performs the (Adam) update, and then projects it back.\n\n\nGood paper and recommended.\nNeed to read more thoroughly."
  },
  {
    "objectID": "diary/daily-reading/2024-03-18.html",
    "href": "diary/daily-reading/2024-03-18.html",
    "title": "ModelGPT - a recent work actively reaching out for collaboration",
    "section": "",
    "text": "Tang, Z., Lv, Z., Zhang, S., Wu, F., Kuang, K., 2024. ModelGPT: Unleashing LLM’s Capabilities for Tailored Model Generation.\n\nTang et al. (2024) propose ModelGPT, a method for generating tailored models from large language models (LLMs).\nHowever, the related work section fails to adequately distinguish their approach from prior methods, especially those that generate adapters for LLMs. The authors seem to overstate their contribution, as the proposed techniques are not fundamentally different from many previous works.\nThe emphasis of “ONLY need ONE ModelGPT to solve all the tasks in one experiment” is pointless, as this is what hypernetworks are designed for and many works have already done it.\nThe text makes excessive use of boldfacing and the assertion of being “the first work in this field” appears overconfident, given the substantial existing literature on model generation using instruction descriptions.\nWhile combining the ideas of hypernetworks from NLP and CV may represent a new direction, it is not especially exciting or a breakthrough, contrary to the authors’ claims, as they do not actually combine the two but rather build different hypermodels for NLP and CV tasks.\n\nI would not recommend reading it or collaborating on this topic, as the gap between the claims and reality appears quite wide."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Date\n\n\n\nTitle\n\n\n\nCategories\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nnotes on some concentration inequalities\n\n\nnote, probability\n\n\n\n\n\n\nFeb 29, 2024\n\n\nreading notes on paper Batch-ICL Effective, Efficient, and Order-Agnostic In-Context Learning by Zhang et al.\n\n\npaper reading, in-context learning\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMSR AI Seminar: Why Does Deep Learning Perform Deep Learning?\n\n\nnote, research, webinar\n\n\n\n\n\n\nFeb 6, 2023\n\n\nTotal Commander Tips\n\n\nnote, tool, total commander\n\n\n\n\n\n\nSep 11, 2022\n\n\ncalculus review 03\n\n\ncalculus, review\n\n\n\n\n\n\nSep 8, 2022\n\n\nunsupervised model related\n\n\nESL, note\n\n\n\n\n\n\nSep 8, 2022\n\n\nsome papers about multi-view-clustering\n\n\npaper reading, clustering, note\n\n\n\n\n\n\nAug 18, 2022\n\n\nvocabs with simple examples\n\n\nEnglish, vocab, note\n\n\n\n\n\n\nAug 12, 2022\n\n\nPyTorch Notes\n\n\nPyTorch, programming\n\n\n\n\n\n\nAug 9, 2022\n\n\nNotes about Technical Writing\n\n\nwriting, note\n\n\n\n\n\n\nJul 5, 2022\n\n\nprobability review 01\n\n\nprobability\n\n\n\n\n\n\nJun 27, 2022\n\n\ncalculus review 02\n\n\ncalculus, review\n\n\n\n\n\n\nJun 8, 2022\n\n\nparallel algorithm course 10\n\n\nparallel algorithm, note\n\n\n\n\n\n\nJun 1, 2022\n\n\nparallel algorithm course 09\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMay 11, 2022\n\n\nparallel algorithm course 08\n\n\nparallel algorithm, note\n\n\n\n\n\n\nApr 27, 2022\n\n\nparallel algorithm course 07\n\n\nparallel algorithm, note\n\n\n\n\n\n\nApr 23, 2022\n\n\nmidterm exam\n\n\nparallel algorithm, note, exam\n\n\n\n\n\n\nApr 20, 2022\n\n\nparallel algorithm course 06\n\n\nparallel algorithm, note\n\n\n\n\n\n\nApr 6, 2022\n\n\nparallel algorithm course 05\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMar 30, 2022\n\n\nparallel algorithm course 04\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMar 30, 2022\n\n\nUnderstanding Machine Learning 06\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 28, 2022\n\n\ncalculus review 01\n\n\ncalculus, review\n\n\n\n\n\n\nMar 23, 2022\n\n\nparallel algorithm course 03\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMar 21, 2022\n\n\nUnderstanding Machine Learning 05\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 16, 2022\n\n\nparallel algorithm course 02\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMar 16, 2022\n\n\nUnderstanding Machine Learning 04\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 11, 2022\n\n\nUnderstanding Machine Learning 03\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 9, 2022\n\n\nparallel algorithm course 01\n\n\nparallel algorithm, note\n\n\n\n\n\n\nMar 8, 2022\n\n\nvim techs\n\n\nvim, programming\n\n\n\n\n\n\nMar 8, 2022\n\n\nUnderstanding Machine Learning 02\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 7, 2022\n\n\nThe elements of statistical learning 01\n\n\nESL, note\n\n\n\n\n\n\nMar 3, 2022\n\n\nMoCo\n\n\npaper reading\n\n\n\n\n\n\nMar 3, 2022\n\n\nUnderstanding Machine Learning 01\n\n\nunderstanding machine learning, note\n\n\n\n\n\n\nMar 1, 2022\n\n\nmy first post\n\n\ntest\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/english/vocab-example.html",
    "href": "posts/english/vocab-example.html",
    "title": "vocabs with simple examples",
    "section": "",
    "text": "some words with explanations (in Eng.) and simple examples\nall the contents are from Combridge Dictionary, I just did some picking up"
  },
  {
    "objectID": "posts/english/vocab-example.html#relate",
    "href": "posts/english/vocab-example.html#relate",
    "title": "vocabs with simple examples",
    "section": "relate",
    "text": "relate\nto be able to understand a situation or someone’s feelings because you have experienced something similar yourself:\n\nI often wake very early - I’m sure most readers over 50 can relate\n\nto tell a story or describe a series of events:\n\nShe related the events of the previous week to the police."
  },
  {
    "objectID": "posts/english/vocab-example.html#persist",
    "href": "posts/english/vocab-example.html#persist",
    "title": "vocabs with simple examples",
    "section": "persist",
    "text": "persist\nIf an unpleasant feeling or situation persists, it continues to exist:\n\nIf the pain persists, consult a doctor.\nThe cold weather is set to persist throughout the week.\n\nto try to do or continue doing something in a determined but often unreasonable way:\n\nIf he persists in asking awkward questions, then send him to the boss"
  },
  {
    "objectID": "posts/english/vocab-example.html#holistically",
    "href": "posts/english/vocab-example.html#holistically",
    "title": "vocabs with simple examples",
    "section": "holistically",
    "text": "holistically\nin a way that deals with or treats the whole of something or someone and not just a part:\n\nThe problem needs to be addressed holistically.\nNutrition is being viewed more holistically as a health issue."
  },
  {
    "objectID": "posts/english/vocab-example.html#entice",
    "href": "posts/english/vocab-example.html#entice",
    "title": "vocabs with simple examples",
    "section": "entice",
    "text": "entice\nto persuade someone to do something by offering them something pleasant:\n\nThe adverts entice the customer into buying things they don’t really want.\nPeople are being enticed away from the profession by higher salaries elsewhere.\nA smell of coffee in the doorway enticed people to enter the shop."
  },
  {
    "objectID": "posts/english/vocab-example.html#embrace",
    "href": "posts/english/vocab-example.html#embrace",
    "title": "vocabs with simple examples",
    "section": "embrace",
    "text": "embrace\nto accept something enthusiastically:\n\nThis was an opportunity that he would embrace.\n\nto hold someone tightly with both arms to express love, liking, or sympathy, or when greeting or leaving someone:\n\nShe saw them embrace on the station platform.\n\nto include something, often as one of a number of things:\n\nLinguistics embraces a diverse range of subjects such as phonetics and stylistics."
  },
  {
    "objectID": "posts/english/vocab-example.html#bolster",
    "href": "posts/english/vocab-example.html#bolster",
    "title": "vocabs with simple examples",
    "section": "bolster",
    "text": "bolster\nto support or improve something or make it stronger:\n\nMore money is needed to bolster the industry."
  },
  {
    "objectID": "posts/english/vocab-example.html#surveillance",
    "href": "posts/english/vocab-example.html#surveillance",
    "title": "vocabs with simple examples",
    "section": "surveillance",
    "text": "surveillance\nthe careful watching of a person or place, especially by the police or army, because of a crime that has happened or is expected:\n\nThe police have kept the nightclub under surveillance because of suspected illegal drug activity."
  },
  {
    "objectID": "posts/english/vocab-example.html#antibiotic",
    "href": "posts/english/vocab-example.html#antibiotic",
    "title": "vocabs with simple examples",
    "section": "antibiotic",
    "text": "antibiotic\na medicine that can destroy harmful bacteria or limit their growth\n\nI’m taking antibiotics for a throat infection."
  },
  {
    "objectID": "posts/english/vocab-example.html#radiate",
    "href": "posts/english/vocab-example.html#radiate",
    "title": "vocabs with simple examples",
    "section": "radiate",
    "text": "radiate\nto produce heat and light\n\nThe planet Jupiter radiates twice as much heat from inside as it receives from the Sun.\n\nto show an emotion or quality, or (of an emotion or quality) to be shown or felt:\n\nHe was radiating joy and happiness."
  },
  {
    "objectID": "posts/english/vocab-example.html#voyage",
    "href": "posts/english/vocab-example.html#voyage",
    "title": "vocabs with simple examples",
    "section": "voyage",
    "text": "voyage\na long journey, especially by ship\n\nHe was a young sailor on his first sea voyage.\n\nto travel\n\nIn their little boat they planned to voyage to distant lands."
  },
  {
    "objectID": "posts/english/vocab-example.html#invert",
    "href": "posts/english/vocab-example.html#invert",
    "title": "vocabs with simple examples",
    "section": "invert",
    "text": "invert\nto turn sth. upside down or change the order of two things\n\nIn some languages, the word order in questions is inverted"
  },
  {
    "objectID": "posts/english/vocab-example.html#constitution",
    "href": "posts/english/vocab-example.html#constitution",
    "title": "vocabs with simple examples",
    "section": "constitution",
    "text": "constitution\nthe set of political principles\nthe general state of someone’s health:\n\nHe has a very strong constitution.\n\nhow something is made up of different parts:\n\nthe constitution of a chemical compound"
  },
  {
    "objectID": "posts/english/vocab-example.html#stuffy",
    "href": "posts/english/vocab-example.html#stuffy",
    "title": "vocabs with simple examples",
    "section": "stuffy",
    "text": "stuffy\nA stuffy room or building is unpleasant because it has no fresh air:\n\nIt’s really hot and stuffy in here - let’s open the window.\n\nold-fashioned, formal, and boring:\n\nShe is trying to promote a less stuffy image of librarians.\n\nstuffy nose"
  },
  {
    "objectID": "posts/english/vocab-example.html#propagate",
    "href": "posts/english/vocab-example.html#propagate",
    "title": "vocabs with simple examples",
    "section": "propagate",
    "text": "propagate\nproduce a new plant using a parent plant (or animal)\nto spread opinions, lies, or beliefs among a lot of people:\n\nThe government have tried to propagate the belief that this is a just war.\n\nto send out or spread light or sound waves, movement, etc., or to be sent out or spread:\n\nHow are sound waves propagated?"
  },
  {
    "objectID": "posts/english/vocab-example.html#penalize",
    "href": "posts/english/vocab-example.html#penalize",
    "title": "vocabs with simple examples",
    "section": "penalize",
    "text": "penalize\nto cause someone a disadvantage:\n\nThe present tax system penalizes poor people.\n\nto punish someone, esp. for breaking the law or a rule:\n\nThe new law penalizes the taxpayers who can least afford to pay."
  },
  {
    "objectID": "posts/english/vocab-example.html#graze",
    "href": "posts/english/vocab-example.html#graze",
    "title": "vocabs with simple examples",
    "section": "graze",
    "text": "graze\nto break the surface of the skin by rubbing against something rough:\n\nHe fell down and grazed his knee.\n\nIf an object grazes something, it touches its surface lightly when it passes it:\n\nThe aircraft’s landing gear grazed the treetops as it landed.\n\neat grass\ninjury"
  },
  {
    "objectID": "posts/english/vocab-example.html#sustain",
    "href": "posts/english/vocab-example.html#sustain",
    "title": "vocabs with simple examples",
    "section": "sustain",
    "text": "sustain\nto cause or allow something to continue for a period of time:\n\nThe economy looks set to sustain its growth into next year.\n\nto keep alive\n\nThe soil in this part of the world is not rich enough to sustain a large population.\n\nto suffer or experience, especially damage or loss:\n\nShe sustained multiple injuries in the accident.\n\nto support emotionally:\n\nShe was sustained by the strength of her religious faith."
  },
  {
    "objectID": "posts/english/vocab-example.html#steer",
    "href": "posts/english/vocab-example.html#steer",
    "title": "vocabs with simple examples",
    "section": "steer",
    "text": "steer\nto control the direction of a vehicle\n\nThis car is very easy to steer.\n\nIf a vehicle steers, it follows a particular route or direction:\n\nThe ship passed Land’s End, in Cornwall, then steered towards southern Ireland.\n\nto take or make sb./sth. go in the direction you want them\n\nShe steered her guests into the dining room."
  },
  {
    "objectID": "posts/english/vocab-example.html#comprise",
    "href": "posts/english/vocab-example.html#comprise",
    "title": "vocabs with simple examples",
    "section": "comprise",
    "text": "comprise\nto have things or people as parts or members; to consist of:\n\nThe course comprises a class book, a practice book, and a CD.\n\nto be the parts or members of something; to make up something:\n\nItalian students comprise 60 percent of the class.\nThe class is comprised mainly of Italian and French students."
  },
  {
    "objectID": "posts/english/vocab-example.html#prosper",
    "href": "posts/english/vocab-example.html#prosper",
    "title": "vocabs with simple examples",
    "section": "prosper",
    "text": "prosper\nto be or become successful, especially financially:\n\nLots of microchip manufacturing companies prospered at that time."
  },
  {
    "objectID": "posts/english/vocab-example.html#compromise",
    "href": "posts/english/vocab-example.html#compromise",
    "title": "vocabs with simple examples",
    "section": "compromise",
    "text": "compromise\nan agreement in an argument in which the people involved reduce their demands or change their opinion in order to agree:\n\nIt is hoped that a compromise will be reached in today’s talks.\nIn a compromise between management and unions, a four percent pay rise was agreed in return for an increase in productivity.\n\nto allow your principles to be less strong or your standards or morals to be lower:\n\nDon’t compromise your beliefs/principles for the sake of being accepted.\nIf we back down on this issue, our reputation will be compromised.\n\nto risk having a harmful effect on something:\n\nWe would never compromise the safety of our passengers."
  },
  {
    "objectID": "posts/english/vocab-example.html#manufacture",
    "href": "posts/english/vocab-example.html#manufacture",
    "title": "vocabs with simple examples",
    "section": "manufacture",
    "text": "manufacture\nto produce goods in large numbers, usually in a factory using machines:\n\nHe works for a company that manufactures car parts.\nThe report notes a rapid decline in manufactured goods.\n\nto invent something, such as an excuse or story, in order to deceive someone:\n\nShe insisted that every scandalous detail of the story had been manufactured.\n\nthe process of producing goods:\n\nOil is used in the manufacture of a number of fabrics."
  },
  {
    "objectID": "posts/english/vocab-example.html#revelation",
    "href": "posts/english/vocab-example.html#revelation",
    "title": "vocabs with simple examples",
    "section": "revelation",
    "text": "revelation\nthe act of making something known that was secret, or a fact that is made known:\n\na moment of revelation\nHis wife divorced him after the revelation that he was having an affair."
  },
  {
    "objectID": "posts/english/vocab-example.html#impart",
    "href": "posts/english/vocab-example.html#impart",
    "title": "vocabs with simple examples",
    "section": "impart",
    "text": "impart\nto communicate information to someone:\n\nto impart the bad news\nI was rather quiet as I didn’t feel I had much wisdom to impart on the subject.\n\nto give something a particular feeling, quality, or taste:\n\nPreservatives can impart colour and flavour to a product."
  },
  {
    "objectID": "posts/english/vocab-example.html#concession",
    "href": "posts/english/vocab-example.html#concession",
    "title": "vocabs with simple examples",
    "section": "concession",
    "text": "concession\nsomething that is allowed or given up, often in order to end a disagreement, or the act of allowing or giving this:\n\nBoth sides involved in the conflict made some concessions in yesterday’s talks.\nHe stated firmly that no concessions will be made to the terrorists.\n\nthe act of admitting defeat:\n\nThe former president’s concession came even before all the votes had been counted.\na concession speech\n\na reduction in the usual price of something, made available to students, old people, etc.:\n\nYou can get travel concessions if you are under 26."
  },
  {
    "objectID": "posts/english/vocab-example.html#trigger",
    "href": "posts/english/vocab-example.html#trigger",
    "title": "vocabs with simple examples",
    "section": "trigger",
    "text": "trigger\na part of a gun that causes the gun to fire when pressed:\n\nIt’s not clear who actually pulled the trigger.\n\nan event or situation, etc. that causes something to start:\n\nThere are fears that the incident may be a trigger for more violence in the capital.\n\nsomething that causes someone to feel upset and frightened because they are made to remember something bad that has happened in the past:\n\nA trigger is something that sets off a flashback, transporting the person back to the traumatic event.\n\nto cause something to start:\n\nSome people find that certain foods trigger their headaches.\nUltraviolet-B radiation triggers the skin to produce vitamin D.\nThe racial killings at the weekend have triggered off a wave of protests.\n\nto cause a strong emotional reaction of fear, shock, anger, or worry in someone, especially because they are made to remember something bad that has happened in the past:\n\nSeeing him come towards me just triggered me and I screamed.\nHe could be triggered by a loud noise."
  },
  {
    "objectID": "posts/english/vocab-example.html#conform",
    "href": "posts/english/vocab-example.html#conform",
    "title": "vocabs with simple examples",
    "section": "conform",
    "text": "conform\nto behave according to the usual standards of behaviour that are expected by a group or society:\n\nAt our school, you were required to conform, and there was no place for originality."
  },
  {
    "objectID": "posts/english/vocab-example.html#deduce",
    "href": "posts/english/vocab-example.html#deduce",
    "title": "vocabs with simple examples",
    "section": "deduce",
    "text": "deduce\nto reach an answer or a decision by thinking carefully about the known facts:\n\nWe cannot deduce very much from these figures.\nThe police have deduced that he must have left his apartment yesterday evening."
  },
  {
    "objectID": "posts/english/vocab-example.html#antiseptic",
    "href": "posts/english/vocab-example.html#antiseptic",
    "title": "vocabs with simple examples",
    "section": "antiseptic",
    "text": "antiseptic\na chemical used for preventing infection in an injury, especially by killing bacteria:\n\nAntiseptic is used to sterilize the skin before giving an injection.\nMany of the ingredients for antiseptics come from the rainforests.\n\ncompletely free from infection:\n\nIn the 1870s and 1880s, doctors began to follow the principles of antiseptic surgery.\n\ntoo clean and showing no imagination and character:\n\nThere’s an antiseptic feeling to the new town centre, with its covered shopping mall."
  },
  {
    "objectID": "posts/english/vocab-example.html#patronage",
    "href": "posts/english/vocab-example.html#patronage",
    "title": "vocabs with simple examples",
    "section": "patronage",
    "text": "patronage\nthe support given to an organization by someone:\n\nThe charity enjoys the patronage of many prominent local business people.\n\nthe power of a person to give someone an important job or position:\n\nPatronage is a potent force if used politically."
  },
  {
    "objectID": "posts/english/vocab-example.html#whip",
    "href": "posts/english/vocab-example.html#whip",
    "title": "vocabs with simple examples",
    "section": "whip",
    "text": "whip\nto bring or take something quickly:\n\nShe whipped a handkerchief out of her pocket and wiped his face.\nHe whipped the covers off the bed.\nI was going to pay but before I knew it he’d whipped out his credit card.\nThey whipped my plate away before I’d even finished.\n\nto (cause something to) move quickly and forcefully:\n\nThe wind whipped across the half-frozen lake.\nA fierce, freezing wind whipped torrential rain into their faces.\n\nto beat food, especially cream, with a special piece of equipment in order to make it thick and firm:\n\nCould you whip the cream for me?\nTry whipping a little brandy or other liqueur into the cream.\nTop with whipped cream and a sprinkle of sugar.\n\nto hit a person or animal with a whip:\n\nI don’t like the way the drivers whip their horses.\n\nto defeat a person or a team in a competition, especially in a sport:\n\nThey beat us last time, but we whipped them in a rematch.\nHe whipped him in their fight two years ago."
  },
  {
    "objectID": "posts/english/vocab-example.html#perquisite",
    "href": "posts/english/vocab-example.html#perquisite",
    "title": "vocabs with simple examples",
    "section": "perquisite",
    "text": "perquisite\nan advantage or something extra, such as money or goods, that you are given because of your job:\n\nThe perquisites of this job include health insurance and a performance bonus."
  },
  {
    "objectID": "posts/english/vocab-example.html#elaborate",
    "href": "posts/english/vocab-example.html#elaborate",
    "title": "vocabs with simple examples",
    "section": "elaborate",
    "text": "elaborate\ncontaining a lot of careful detail or many detailed parts:\n\nYou want a plain blouse to go with that skirt - nothing too elaborate.\nThey’re making the most elaborate preparations for the wedding.\nHe came out with such an elaborate excuse that I didn’t quite believe him.\n\nto add more information to or explain something that you have said:\n\nThe congresswoman said she was resigning, but refused to elaborate on her reasons for doing so."
  },
  {
    "objectID": "posts/english/vocab-example.html#merchandise",
    "href": "posts/english/vocab-example.html#merchandise",
    "title": "vocabs with simple examples",
    "section": "merchandise",
    "text": "merchandise\ngoods that are bought and sold:\n\nShoppers complained about poor quality merchandise and high prices.\nJapan exported $117 billion in merchandise to the US in 1999.\n\nto encourage the sale of goods by advertising them or by making certain that they are noticed:\n\nShe had to merchandise the new product line."
  },
  {
    "objectID": "posts/english/vocab-example.html#dividend",
    "href": "posts/english/vocab-example.html#dividend",
    "title": "vocabs with simple examples",
    "section": "dividend",
    "text": "dividend\n(a part of) the profit of a company that is paid to the people who own shares in it:\n\nDividends will be sent to shareholders.\nIn addition to their salary, employees receive a profit-related dividend."
  },
  {
    "objectID": "posts/english/vocab-example.html#scatter",
    "href": "posts/english/vocab-example.html#scatter",
    "title": "vocabs with simple examples",
    "section": "scatter",
    "text": "scatter\nto (cause to) move far apart in different directions:\n\nThe protesters scattered at the sound of gunshots.\nThe soldiers came in and scattered the crowd.\n\nto cover a surface with things that are far apart and in no particular arrangement:\n\nScatter the powder around the plants.\nI scattered grass seed all over the lawn.\nI scattered the whole lawn with grass seed."
  },
  {
    "objectID": "posts/calculus/calculus-02.html",
    "href": "posts/calculus/calculus-02.html",
    "title": "calculus review 02",
    "section": "",
    "text": "can be used for computing ranks, solving systems of linear equations, etc.\nGiven \\(\\mathbf{A}_{m\\times n}\\mathbf{x}=\\mathbf{b}\\)\n\\([\\mathbf{A}\\mid\\mathbf{b}]\\) row reduces to \\([\\tilde{\\mathbf{A}}\\mid\\tilde{\\mathbf{b}}]\\), determine the case of the solutions.\n\n\n\n\n\n\nNoteextend\n\n\n\nsquare matrix can be approximated by invertible matrices (replace zeros in the diagonal entries of the row reduced matrix with \\(1/n\\)).\n\n\n\n\nthe dim of the image\nrow rank = column rank"
  },
  {
    "objectID": "posts/calculus/calculus-02.html#the-great-row-reduction",
    "href": "posts/calculus/calculus-02.html#the-great-row-reduction",
    "title": "calculus review 02",
    "section": "",
    "text": "can be used for computing ranks, solving systems of linear equations, etc.\nGiven \\(\\mathbf{A}_{m\\times n}\\mathbf{x}=\\mathbf{b}\\)\n\\([\\mathbf{A}\\mid\\mathbf{b}]\\) row reduces to \\([\\tilde{\\mathbf{A}}\\mid\\tilde{\\mathbf{b}}]\\), determine the case of the solutions.\n\n\n\n\n\n\nNoteextend\n\n\n\nsquare matrix can be approximated by invertible matrices (replace zeros in the diagonal entries of the row reduced matrix with \\(1/n\\)).\n\n\n\n\nthe dim of the image\nrow rank = column rank"
  },
  {
    "objectID": "posts/calculus/calculus-02.html#vector-space",
    "href": "posts/calculus/calculus-02.html#vector-space",
    "title": "calculus review 02",
    "section": "Vector Space",
    "text": "Vector Space\n\n“contrete to abstract” function \\(\\Phi_{v}\\)\nA linear transformation from contrete \\(\\mathbb{R}^n\\) coordinate representation to abstract vector space \\(V\\)\n\\[\n\\Phi_{\\{\\mathbf{v}\\}}(\\mathbf{a})=\\Phi_{\\{\\mathbf{v}\\}}\\left(\\begin{matrix}a_1\\\\\\vdots\\\\a_n\\end{matrix}\\right)=a_1\\mathbf{v_1}+\\cdots+a_n\\mathbf{v_n},\n\\]\nwhere \\(\\{\\mathbf{v}\\}\\) is the set of base vectors of \\(V\\).\n\n\nChange of bases \\(P_{\\{\\mathbf{v}'\\}\\to \\{\\mathbf{v}\\}}\\)\n\\[[P_{\\{\\mathbf{v}'\\}\\to\\{\\mathbf{v}\\}}]\\mathbf{a}=\\mathbf{b},\\]\nwhere \\(\\sum_ia_i\\mathbf{v}_i'=\\sum_ib_i\\mathbf{v}_i\\)\nIn other words,\n\\[P_{\\{\\mathbf{v}'\\}\\to \\{\\mathbf{v}\\}}=\\Phi_{\\{\\mathbf{v}'\\}}^{-1}\\Phi_{\\{\\mathbf{v}\\}}\\]"
  },
  {
    "objectID": "posts/calculus/calculus-02.html#eigenvectors-and-eigenvalues",
    "href": "posts/calculus/calculus-02.html#eigenvectors-and-eigenvalues",
    "title": "calculus review 02",
    "section": "Eigenvectors and Eigenvalues",
    "text": "Eigenvectors and Eigenvalues\neigenvectors with different eigenvalues are linearly independent.\ndiagnolization"
  },
  {
    "objectID": "posts/calculus/calculus-02.html#newtons-method",
    "href": "posts/calculus/calculus-02.html#newtons-method",
    "title": "calculus review 02",
    "section": "Newton’s Method",
    "text": "Newton’s Method\nwhy talking about Newton’s Method?\na convenient and practical way to introduce implicit function and inverse function\n\ndef\ntarget: solve for a solution \\(f(x)=0\\)\nstart at \\(a_0\\)\niterate with \\(a_i=a_{i-1}-[Df(a_{i-1})]^{-1}f(a_{i-1})\\)\n\n\n\n\n\n\nNote\n\n\n\nnotes: since \\(f(x)\\approx f(a)+[Df(a)](x-a)\\), letting \\(f(x)=0\\) will give us the next guess.\n\n\nThere is actually a sufficient condition to ensure the convergence.\n\n\nKantorovich’s theorem\nlet \\(a_0\\in\\mathbb{R}^n\\), \\(U\\): open neighborhood of \\(a_0\\) in \\(\\mathbb{R}^n\\), \\(f:U\\to\\mathbb{R}^n\\)\ndef \\(h_0=-[Df(a_0)]^{-1}f(a_0)\\), \\(a_1=a_0+h_0\\), \\(U_1=B_{|h_0|}(a_1)\\), \\(M\\) as the Lipschitz ratio of \\(Df(x)\\) in \\(U_1\\)\ntheorem: if \\(|f(a_0)||[Df(a_0)]^{-1}|^2M\\le\\frac{1}{2}\\), then \\(f(x)=0\\) has a unique solution in the closed ball \\(\\overline{U_1}\\) and Newton’s Method converges to it with initial guess \\(a_0\\).\n\n\n\n\n\n\nNote\n\n\n\nnotes 1: in short, \\(a_1\\) is the next guess\nnotes 2: a valid value of Lipschitz ratio\nIf \\(|D_kD_jf_i(x)|\\le c_{i,j,k}\\)\nthen\n\\[\\left(\\sum_{1\\le i,j,k\\le n}c_{i,j,k}^2\\right)^{1/2}\\]\nis valid\n\n\n\n\nproposition\ndef \\(U_0=\\{x\\mid |x-a_0|\\lt 2|h_0|\\}\\)\nIf \\(Df\\) satisfy Lipschitz condition in \\(U_0\\), then \\(f(x)=0\\) has a unique solution in \\(\\overline{U_0}\\) and Newton’s Method converges to it.\n\n\n\n\n\n\nNote\n\n\n\nIf the product is strictly less than \\(1/2\\), then Newton’s Method superconverges.\nIf \\(|h_n|\\le\\frac{1}{c}\\), for \\(c\\) some constant depend on \\(f\\), then\n\\[|h_{n+m}|\\le \\frac{1}{c}\\cdot\\left(\\frac{1}{2}\\right)^{2m},\\]\nwhere \\(h_i=a_{i+1}-a_{i}\\).\n\n\n\n\nstronger version\nreplace all lengths of matrices with norms.\n\n\n\n\n\n\nNote\n\n\n\nnorm of a matrix \\(A\\)\n\\[\\lVert A\\rVert=\\sup_{|x|=1} |A\\mathbf{x}|\\]\neasy to check: \\(\\lVert A\\rVert\\le |A|\\)"
  },
  {
    "objectID": "posts/calculus/calculus-02.html#inverse-function-theorem",
    "href": "posts/calculus/calculus-02.html#inverse-function-theorem",
    "title": "calculus review 02",
    "section": "inverse function theorem",
    "text": "inverse function theorem\n\\(f\\) is continously differentiable\n\\(Df\\) is invertible at \\(x_0\\)\nthen \\(f\\) is locally invertible, with differentiable inverse in some neighborhood of \\(f(x_0)\\)\n\n\n\n\n\n\nNote\n\n\n\nthe vigorous version is too lengthy, I am not gonna put it here.\nAs you might expect, the locality can actually be quantified by Kantorovich’s theorem."
  },
  {
    "objectID": "posts/calculus/calculus-02.html#implicit-function-theorem",
    "href": "posts/calculus/calculus-02.html#implicit-function-theorem",
    "title": "calculus review 02",
    "section": "implicit function theorem",
    "text": "implicit function theorem\n\\(U\\): a open subset of \\(\\mathbb{R}^{n+m}\\)\n\\(\\mathbf{F}:U\\to\\mathbb{R}^n\\) a \\(C^1\\) mapping s.t. \\(\\mathbf{F}(\\mathbf{c})=0\\) and \\([D\\mathbf{F}(c)]\\) is onto\nthen the system of linear equations \\(D\\mathbf{F}(\\mathbf{x})=0\\) has n pivotal vars and m nonpivotal vars. there exists a neighborhood of \\(\\mathbf{c}\\) where \\(\\mathbf{F}(\\mathbf{c})=0\\) implicitly defines the n passive vars as a function \\(\\mathbf{g}\\) of the m active vars.\n\n\n\n\n\n\nNote\n\n\n\nnotes 1: \\(\\mathbf{F}\\) behaves similar to \\(D\\mathbf{F}\\) locally.\nin a normal system of linear equations \\(\\mathbf{Ax}=0\\), where \\(\\mathbf{x}\\in\\mathbb{R}^{m+n}\\), \\(\\textrm{rank }\\mathbf{A}=n\\), the dimension of the kernel space of \\(\\mathbf{A}\\) is m which corresponds to the m active vars (the base of the kernel).\nnotes 2: again, the rigorous version is a little lengthy.\n\n\nnot like the existence theorem, which only claims the existence of the inverse function or the implicit function, using Newton’s Method gives us a more practical way to find the function and a more quantified result."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-03.html",
    "href": "posts/understanding-machine-learning/UML-03.html",
    "title": "Understanding Machine Learning 03",
    "section": "",
    "text": "Before, the way of choosing \\(m_H\\) and the effect of \\(\\delta\\) was related to the learner. However, we can borrow the concept of uniform convergence from analysis to make it independent of what learner you use.\nhere, we can treat \\(L_S(h)\\) as \\(\\sum_i^nf_i(x)\\) since they are both intermediate vals during the convergence, and \\(L_D(h)\\) to be the final end\n\n\n\\(S\\) is \\(\\epsilon\\)-representation sample (w.r.t domain, \\(H\\), \\(l\\) and \\(D\\)) if\n\\[\n\\forall h\\in\\mathcal{H},\\, |L_S(h)-L_D(h)|\\le \\epsilon\n\\]\nlemma\nif S is \\(\\frac{\\epsilon}{2}\\)-representative, then \\(\\forall h_S\\in\\argmin_{h\\in\\mathcal{H}}L_S(h)\\)\n\\[\nL_D(h_S)\\le \\min_{h\\in\\mathcal{H}}L_D(h)+\\epsilon\n\\]\nthrough this lemma, we can immediately have\n\\(S\\) is \\(\\frac{\\epsilon}{2}\\)-representative with prob \\(1-\\delta\\) \\(\\implies\\) Agnostic PAC learnability\n\n\n\nH has the uniform convergence \\(\\coloneqq\\) exists a func \\(m_H^{UC}(\\epsilon, \\delta)\\), for every \\(D\\), if \\(|S|\\gt m_H^{UC}\\) then with \\(1-\\delta\\) prob, it is \\(\\epsilon\\)-representative\nIt seems stronger than the original agnostic PAC, just like the rel between uniform conv and normal conv in analysis. normal conv only cares the situation in a certain area (here the decider generated by the learner), while uni conv holds on the whole area (all \\(h\\in\\mathcal{H}\\))\n\n\n\\(m_H\\le m_H^{UC}\\) if \\(H\\) has the uni conv property"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-03.html#uniform-convergence",
    "href": "posts/understanding-machine-learning/UML-03.html#uniform-convergence",
    "title": "Understanding Machine Learning 03",
    "section": "",
    "text": "Before, the way of choosing \\(m_H\\) and the effect of \\(\\delta\\) was related to the learner. However, we can borrow the concept of uniform convergence from analysis to make it independent of what learner you use.\nhere, we can treat \\(L_S(h)\\) as \\(\\sum_i^nf_i(x)\\) since they are both intermediate vals during the convergence, and \\(L_D(h)\\) to be the final end\n\n\n\\(S\\) is \\(\\epsilon\\)-representation sample (w.r.t domain, \\(H\\), \\(l\\) and \\(D\\)) if\n\\[\n\\forall h\\in\\mathcal{H},\\, |L_S(h)-L_D(h)|\\le \\epsilon\n\\]\nlemma\nif S is \\(\\frac{\\epsilon}{2}\\)-representative, then \\(\\forall h_S\\in\\argmin_{h\\in\\mathcal{H}}L_S(h)\\)\n\\[\nL_D(h_S)\\le \\min_{h\\in\\mathcal{H}}L_D(h)+\\epsilon\n\\]\nthrough this lemma, we can immediately have\n\\(S\\) is \\(\\frac{\\epsilon}{2}\\)-representative with prob \\(1-\\delta\\) \\(\\implies\\) Agnostic PAC learnability\n\n\n\nH has the uniform convergence \\(\\coloneqq\\) exists a func \\(m_H^{UC}(\\epsilon, \\delta)\\), for every \\(D\\), if \\(|S|\\gt m_H^{UC}\\) then with \\(1-\\delta\\) prob, it is \\(\\epsilon\\)-representative\nIt seems stronger than the original agnostic PAC, just like the rel between uniform conv and normal conv in analysis. normal conv only cares the situation in a certain area (here the decider generated by the learner), while uni conv holds on the whole area (all \\(h\\in\\mathcal{H}\\))\n\n\n\\(m_H\\le m_H^{UC}\\) if \\(H\\) has the uni conv property"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-03.html#situation-of-the-finite-h-class",
    "href": "posts/understanding-machine-learning/UML-03.html#situation-of-the-finite-h-class",
    "title": "Understanding Machine Learning 03",
    "section": "situation of the finite H class",
    "text": "situation of the finite H class\nneed to find \\(m\\), so that\n\\[\nD^m(\\{S:\\forall h\\in \\mathcal{H},|L_S(h)-L_D(h)|\\le\\epsilon\\})\\ge 1-\\delta\n\\]\nand we may convert it into a more familiar form (convenient for using inequalities)\n\\[\nD^m(\\{S:\\exists h\\in \\mathcal{H},|L_S(h)-L_D(h)|\\gt\\epsilon\\})\\lt \\delta\n\\]\nusing union bound and Hodeffing inequalities (note that \\(L_D(h)=\\mathbb{E}_{S\\sim D^m}(L_S(h))\\)), we have\n\\[\nLHS\\le\\sum_{h\\in\\mathcal{H}}2exp(-2m\\epsilon^2)\n\\]\nas a corollary, we have the upper bound for finite hypothesis class which is agnostic PAC learnable\n\\[\nm_H^{UC}(\\epsilon,\\delta)\\le\\left\\lceil\\frac{log(2|\\mathcal{H}|/\\delta)}{2\\epsilon^2}\\right\\rceil\n\\]\n\n\n\n\n\n\nTipsummary\n\n\n\nif uni conv holds, then in most cases, the empirical risks of h in H will faithfully represent their true risks\n\n\n\nexercises\n\n4.1\n\n\n\\(\\forall \\epsilon,\\delta\\gt 0,\\exists m(\\epsilon,\\delta)\\,s.t.\\) \\[\n\\forall m\\ge m(\\epsilon,\\delta),\\,\\mathcal{P}_{S\\sim D^m}[L_D(A(S))\\gt\\epsilon]\\lt\\delta\\]\n\\(\\lim_{m\\to \\infty}\\mathbb{E}_{S\\sim D^m}[L_D(A(S))]=0\\)\n\n1 \\(\\iff\\) 2"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html",
    "href": "posts/understanding-machine-learning/UML-02.html",
    "title": "Understanding Machine Learning 02",
    "section": "",
    "text": "def PAC learnability\nhypothesis H is PAC learnable if realizability assumption holds, and exists \\(m_H(\\epsilon,\\delta)\\rightarrow\\mathbb{N}\\)\nwhere with #i.i.d. sample \\(\\ge m_H\\), we always have a probability approx correct h just using ERM."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html#def-pac",
    "href": "posts/understanding-machine-learning/UML-02.html#def-pac",
    "title": "Understanding Machine Learning 02",
    "section": "",
    "text": "def PAC learnability\nhypothesis H is PAC learnable if realizability assumption holds, and exists \\(m_H(\\epsilon,\\delta)\\rightarrow\\mathbb{N}\\)\nwhere with #i.i.d. sample \\(\\ge m_H\\), we always have a probability approx correct h just using ERM."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html#removing-realizability-assumption",
    "href": "posts/understanding-machine-learning/UML-02.html#removing-realizability-assumption",
    "title": "Understanding Machine Learning 02",
    "section": "removing realizability assumption",
    "text": "removing realizability assumption\nthe realizability assumption is too strong and unrealistic where we assume the existence of a perfect hypothesis from \\(\\mathcal{H}\\) that can reveal ground truth \\(f\\) with \\(Pr=1\\)\nso, change \\(f(x)\\) into a joint distrib \\(D(x,y)\\) as most researchers would do\ndef generalized risk as \\(L_D(h)\\coloneqq \\mathcal{P}_{(x,y)\\sim D}[h(x)\\neq y]\\coloneqq D(\\{(x,y):h(x)\\neq y\\})\\), just changed \\(D\\) into a joint distrib\nempirical risk is the same\nstill, when take \\(D\\) to be a uniform distrib on \\(S\\) they are eq\nideally, func “\\(f_D(x)=1\\text{ if }Pr[y=1|x]\\ge 0.5\\text{ and 0 otherwise}\\)” is the optimal sol to the gen risk min problem when \\(\\mathcal{Y}=\\{0,1\\}\\), w.r.t 0-1 loss. Bayes optimal sol.\n\nnote: my stupid short proof about the above\nwe need to proof\n\\[\n[f(x)\\neq 0]Pr(y=0|x)+[f(x)\\neq 1]Pr(y=1|x)\\\\\n\\le [g(x)\\neq 0]Pr(y=0|x)\\dots\n\\]\njust consider cond on \\(Pr(y=0|x)\\gt 0.5\\), and it becomes\n\\[\nLHS=Pr(y=1|x)\\\\\n=\\{[g(x)\\neq 0]+[g(x)\\neq 1]\\}Pr(y=1|x)\\\\\n\\le RHS\n\\]\nvery ugly and not clever proof :/ \\(\\blacksquare\\)\n\nhere, we still have the opt function \\(f\\), which minimizes the gen risk but does not minimize it to zero"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html#def-agnostic不可知论的-pac-learnability",
    "href": "posts/understanding-machine-learning/UML-02.html#def-agnostic不可知论的-pac-learnability",
    "title": "Understanding Machine Learning 02",
    "section": "def Agnostic(不可知论的) PAC learnability",
    "text": "def Agnostic(不可知论的) PAC learnability\nbefore: \\(L_{D,f}(h)\\le \\epsilon\\), now: \\(L_{D}(h)\\le min_{g\\in\\mathcal{H}}L_{D}(g)+\\epsilon\\)\nso \\(f\\) above will not be used, but the joint distrib \\(D\\) instead\nand we see that if the realizability assumption holds, it’s the same as the original PAC learnability\nagnostic just means we can’t obtain an h with arbitrary small gen risk\nrelative best instead of abs best"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html#other-loss-functions",
    "href": "posts/understanding-machine-learning/UML-02.html#other-loss-functions",
    "title": "Understanding Machine Learning 02",
    "section": "other loss functions",
    "text": "other loss functions\nwe can actually use other measures in place of the 0-1 loss, especially in regression problems\nnaturally, we can extend the loss function into a more formal definition, \\(l:\\mathcal{H}\\times\\mathcal{Z}\\rightarrow \\mathbb{R}_+\\), where \\(\\mathcal{Z}\\) is the set of instances, in prediction tasks, it could be \\(\\mathcal{X}\\times\\mathcal{Y}\\)\n\nAgnostic PAC learnability for General Loss Functions\n\\(L_D(h)\\le\\min_{h'\\in\\mathcal{H}}L_D(h')+\\epsilon\\)\nwhere \\(L_D(h)=\\mathcal{E}_{z\\sim D}[l(h,z)]\\)\nnote: \\(l(h,\\dot)\\) is a rand var, it should be measurable.."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-02.html#some-exercises",
    "href": "posts/understanding-machine-learning/UML-02.html#some-exercises",
    "title": "Understanding Machine Learning 02",
    "section": "some exercises",
    "text": "some exercises\n\n3.1. about monotonicity of \\(m_\\mathcal{H}\\) on \\(\\epsilon\\) and \\(\\delta\\) respectively: seems trivial\n3.2. about \\(\\mathcal{H}_{singleton}\\): first, you need to come up with a simple learning alg. if no pos samples appear, just choose \\(h^-\\). this is enough to prove the PAC learnability, as m is large enough, the cost will be small enough\n3.3. about \\(\\mathcal{H}\\) consist of disks. similar to the rect situation from this chap, but simpler, ’cause it’s convenient to construct how the bad samples look like\n3.4. about \\(\\mathcal{H}\\) consist of boolean conjunctions. similar to 3.2. it’s easy to determine f if \\(S\\) contains a positive sample. Otherwise, we just return an all-negative hypothesis\n3.5. about samples from i. but not i.d. from the derivation of the finite hypo corollary, the key is to deal with \\(\\prod_i \\mathcal{P}_{x\\in D_i}(x_i|h(x_i)=f(x_i))\\), where the GA mean ineq could be used to make it as \\((1-\\epsilon)^m\\)\n3.6. ??, since you added the realizability assumption, it’s naive to have the PAC learnability, maybe?\n3.7. about ideally opt sol of binary classification (w.r.t 0-1 loss). see this\n3.8.1. same question as above, but use abs loss, and consider probabilistic hypothesis (outputs a distribution instead of the deterministic answer), method from here seems enough?\n3.8.2. prove the existence of a learning algo that is better than any others provided \\(D\\). ??? an algo from God that can directly output \\(f\\) from the previous question -_-\n3.8.3. for every learning algo A from \\(D\\), there always exists a B and \\(D'\\) that A is not better than B on \\(D\\). shit, this is also naive from 3.8.2\n3.9. about a variant of PAC learnability, which uses a two-oracle model that allows learner access to \\(D^+\\) and \\(D^-\\) on its preference. the learner can actually change the popularity of the observances, e.g. a learner can take samples from both pos and neg with equal probability (I don’t understand here so much, does )\n\n\nproof PAC in the standard model \\(\\implies\\) PAC in the two-oracle model. we need to construct a learner from the one in the standard model. suppose the learner puts equal weights on pos and neg samples. It learns a population with equal pos and neg using a standard model. denote the new distribution as \\(D'\\), so\n\n\n\\[\\begin{aligned}\nL_{D'}(h)&=P_{D'}[h\\neq f,f=0]+P_{D'}[h\\neq f, f=1]\\\\\n&=P_{D'}[f=0]P_D[h\\neq f|f=0]+P_{D'}[f=1]P_D[h\\neq f|f=1]\\\\\n&=\\frac{1}{2} L_{D^+}(h)+\\frac{1}{2}L_{D^-}(h)\n\\end{aligned}\n\\]\n\n\nproof PAC in the two-oracle model \\(\\implies\\) PAC in the standard model if \\(h^+,h^-\\in\\mathcal{H}\\). if we have enough samples (\\(m_H\\)), it will contain \\(m^+\\) pos, and \\(m^-\\) neg with high prob, and even it fails to have enough pos (or neg), we can just return \\(h^-\\) ((\\(h^+\\)) and won’t cost much risk."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-04.html",
    "href": "posts/understanding-machine-learning/UML-04.html",
    "title": "Understanding Machine Learning 04",
    "section": "",
    "text": "What is a universal learner? It means it doesn’t need any prior knowledge. To be more specific, \\(\\mathcal{H}\\) that contains all possible functions is PAC-learnable. ? that is certainly not true since this is about the NFL theorem.\nTypically, prior knowledge could be assumptions of knowing \\(\\mathcal{D}\\) comes from some family of distribution or assuming \\(\\exists h\\in\\mathcal{H}\\) that \\(L_D(h)\\) is small enough.\n\n\nwe consider binary classification problem and 0-1 loss over \\(\\mathcal{X}\\)\n\\(m\\) be the tr set size smaller than \\(\\frac{|\\mathcal{X}|}{2}\\), A be any learner\nthere is a D that\n\nthere exists \\(f\\), with zero error on \\(\\mathcal{D}\\)\nwith a probability of at least 1/7 over the choice of \\(S\\sim \\mathcal{D}^m\\) we have the error of \\(A(S)\\ge 1/8\\)\n\nLet’s prove this famous theorem!!!\n\nlet C be a subset of \\(\\mathcal{X}\\) with size 2m as the finite ‘domain’ we will consider\nthe intuition is that since the learner can only see at most half of the domain set, we can then make the other part of distribution anything we want to defeat A\nwe need to find the D and f\nthere could be like \\(2^{2m}\\) possible f’s; we can prove that\n\\[\n\\max_{D,f}\\mathbb{E}_{S\\sim D^m}[L_{D,f}(A(S))]\\ge 1/4\n\\]\nwhich means there exists some bad f that will make A fail\nnote D and f should be matched, so we construct \\(D_i\\) as follows for each \\(f_i\\), \\(i=1\\dots T\\) where \\(T=2^{2m}\\)\n\\[\nD_i(x,y) = \\begin{cases}\n            1/|C| &\\text{if } f_i(x)=y \\\\\n            0 &\\text{otherwise}\n           \\end{cases}\n\\]\nsince \\(C\\) is finite, we can enumerate all S\ndenote as \\(S_i\\), \\(i=1\\dots M\\) where \\(M=(2m)^m\\), note instances in S can be duplicated\n\\[\n\\begin{aligned}\n   &\\max_i\\mathbb{E}_{S\\sim D_i}[L_{D_i}(A(S))]\\\\\n   &=\\frac{1}{M}\\max_i\\sum_j^ML_{D_i}(A(S_j^i))\\\\\n   &\\ge\\frac{1}{MT}\\sum_i^T\\sum_j^ML_{D_i}(A(S_j^i))\\\\\n   &=\\frac{1}{TM}\\sum_j^M\\sum_i^TL_{D_i}(A(S_j^i))\\\\\n   &\\ge\\frac{1}{T}\\min_j\\sum_{i}^{T}L_{D_i}(A(S_j^i))\n\\end{aligned}\n\\]\nhere the \\(i\\) in \\(S_j^i\\) means the label is assigned by \\(D_i\\), hence \\(f_i\\)\nWe now convert the problem of finding the \\(f\\) into \\(S_j^i\\) that has a significant error averaged on all functions. Intuitively, since we consider all functions, they must have some disagreement on the samples\nfor \\(S_j^i\\), we let \\(P=\\{x_i\\in C|x_i\\notin S_j^i\\}\\) and \\(p=|P|\\), where \\(p\\ge m\\)\n\\[\n\\begin{aligned}\n    &L_{D_i}(A(S_j^i))\\\\\n    =&\\frac{1}{2m}\\sum_k^{2m}\\mathbf{1}[f_i(x_k)\\neq A(S_j^i)(x_k)]\\\\\n    \\ge&\\frac{1}{2p}\\sum_{x\\in P}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n\\end{aligned}\n\\]\nthen\n\\[\n\\begin{aligned}\n    &\\frac{1}{T}\\sum_{i}^{T}L_{D_i}(A(S_j^i))\\\\\n    \\ge&\\frac{1}{T}\\sum_i^T\\frac{1}{2p}\\sum_{x\\in P}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n    =&\\frac{1}{2}*\\frac{1}{p}\\sum_{x\\in P}\\frac{1}{T}\\sum_{i}^{T}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n\\end{aligned}\n\\]\nthere are details here, note we have removed out the instances that are in \\(S_j\\) (no \\(i\\) here), that is because \\(\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\) will always be zero if \\(x\\in S_j\\) and we can certainly not consider them\nsecond, since we take \\(f\\) from func space that contains all possible funcs, so they can be separated into pairs that can cancellate each other\nthere must always exist a pair of f’s (\\(f_a\\) and \\(f_b\\)) that only differ on one instance \\(x\\) which is not in \\(S_j\\) (\\(x\\in P\\))\ns.t.\n\\(\\mathbf{1}[f_a(x)\\neq A(S_j^a)(x)]+\\mathbf{1}[f_b(x)\\neq A(S_j^b)(x)]=1\\)\nthen the ave above actually is \\(\\frac{1}{4}\\)\nnow we have proved that\n\\[\n\\max_{D,f}\\mathbb{E}_{S\\sim D^m}[L_{D,f}(A(S))]\\ge 1/4\n\\]\nuse some prob inequality can give us the conclusion that \\(\\exists D\\) \\[\n\\mathbb{P}_{S\\sim D^m}[L_D(A(S))\\ge1/8]\\ge1/7\n\\]\n\nusing the def, \\(H\\) that contains every possible h is not PAC learnable"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-04.html#no-free-lunch-theorem",
    "href": "posts/understanding-machine-learning/UML-04.html#no-free-lunch-theorem",
    "title": "Understanding Machine Learning 04",
    "section": "",
    "text": "What is a universal learner? It means it doesn’t need any prior knowledge. To be more specific, \\(\\mathcal{H}\\) that contains all possible functions is PAC-learnable. ? that is certainly not true since this is about the NFL theorem.\nTypically, prior knowledge could be assumptions of knowing \\(\\mathcal{D}\\) comes from some family of distribution or assuming \\(\\exists h\\in\\mathcal{H}\\) that \\(L_D(h)\\) is small enough.\n\n\nwe consider binary classification problem and 0-1 loss over \\(\\mathcal{X}\\)\n\\(m\\) be the tr set size smaller than \\(\\frac{|\\mathcal{X}|}{2}\\), A be any learner\nthere is a D that\n\nthere exists \\(f\\), with zero error on \\(\\mathcal{D}\\)\nwith a probability of at least 1/7 over the choice of \\(S\\sim \\mathcal{D}^m\\) we have the error of \\(A(S)\\ge 1/8\\)\n\nLet’s prove this famous theorem!!!\n\nlet C be a subset of \\(\\mathcal{X}\\) with size 2m as the finite ‘domain’ we will consider\nthe intuition is that since the learner can only see at most half of the domain set, we can then make the other part of distribution anything we want to defeat A\nwe need to find the D and f\nthere could be like \\(2^{2m}\\) possible f’s; we can prove that\n\\[\n\\max_{D,f}\\mathbb{E}_{S\\sim D^m}[L_{D,f}(A(S))]\\ge 1/4\n\\]\nwhich means there exists some bad f that will make A fail\nnote D and f should be matched, so we construct \\(D_i\\) as follows for each \\(f_i\\), \\(i=1\\dots T\\) where \\(T=2^{2m}\\)\n\\[\nD_i(x,y) = \\begin{cases}\n            1/|C| &\\text{if } f_i(x)=y \\\\\n            0 &\\text{otherwise}\n           \\end{cases}\n\\]\nsince \\(C\\) is finite, we can enumerate all S\ndenote as \\(S_i\\), \\(i=1\\dots M\\) where \\(M=(2m)^m\\), note instances in S can be duplicated\n\\[\n\\begin{aligned}\n   &\\max_i\\mathbb{E}_{S\\sim D_i}[L_{D_i}(A(S))]\\\\\n   &=\\frac{1}{M}\\max_i\\sum_j^ML_{D_i}(A(S_j^i))\\\\\n   &\\ge\\frac{1}{MT}\\sum_i^T\\sum_j^ML_{D_i}(A(S_j^i))\\\\\n   &=\\frac{1}{TM}\\sum_j^M\\sum_i^TL_{D_i}(A(S_j^i))\\\\\n   &\\ge\\frac{1}{T}\\min_j\\sum_{i}^{T}L_{D_i}(A(S_j^i))\n\\end{aligned}\n\\]\nhere the \\(i\\) in \\(S_j^i\\) means the label is assigned by \\(D_i\\), hence \\(f_i\\)\nWe now convert the problem of finding the \\(f\\) into \\(S_j^i\\) that has a significant error averaged on all functions. Intuitively, since we consider all functions, they must have some disagreement on the samples\nfor \\(S_j^i\\), we let \\(P=\\{x_i\\in C|x_i\\notin S_j^i\\}\\) and \\(p=|P|\\), where \\(p\\ge m\\)\n\\[\n\\begin{aligned}\n    &L_{D_i}(A(S_j^i))\\\\\n    =&\\frac{1}{2m}\\sum_k^{2m}\\mathbf{1}[f_i(x_k)\\neq A(S_j^i)(x_k)]\\\\\n    \\ge&\\frac{1}{2p}\\sum_{x\\in P}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n\\end{aligned}\n\\]\nthen\n\\[\n\\begin{aligned}\n    &\\frac{1}{T}\\sum_{i}^{T}L_{D_i}(A(S_j^i))\\\\\n    \\ge&\\frac{1}{T}\\sum_i^T\\frac{1}{2p}\\sum_{x\\in P}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n    =&\\frac{1}{2}*\\frac{1}{p}\\sum_{x\\in P}\\frac{1}{T}\\sum_{i}^{T}\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\\\\n\\end{aligned}\n\\]\nthere are details here, note we have removed out the instances that are in \\(S_j\\) (no \\(i\\) here), that is because \\(\\mathbf{1}[f_i(x)\\neq A(S_j^i)(x)]\\) will always be zero if \\(x\\in S_j\\) and we can certainly not consider them\nsecond, since we take \\(f\\) from func space that contains all possible funcs, so they can be separated into pairs that can cancellate each other\nthere must always exist a pair of f’s (\\(f_a\\) and \\(f_b\\)) that only differ on one instance \\(x\\) which is not in \\(S_j\\) (\\(x\\in P\\))\ns.t.\n\\(\\mathbf{1}[f_a(x)\\neq A(S_j^a)(x)]+\\mathbf{1}[f_b(x)\\neq A(S_j^b)(x)]=1\\)\nthen the ave above actually is \\(\\frac{1}{4}\\)\nnow we have proved that\n\\[\n\\max_{D,f}\\mathbb{E}_{S\\sim D^m}[L_{D,f}(A(S))]\\ge 1/4\n\\]\nuse some prob inequality can give us the conclusion that \\(\\exists D\\) \\[\n\\mathbb{P}_{S\\sim D^m}[L_D(A(S))\\ge1/8]\\ge1/7\n\\]\n\nusing the def, \\(H\\) that contains every possible h is not PAC learnable"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-04.html#bias-complexity-trade-off",
    "href": "posts/understanding-machine-learning/UML-04.html#bias-complexity-trade-off",
    "title": "Understanding Machine Learning 04",
    "section": "bias-complexity trade-off",
    "text": "bias-complexity trade-off\nUsually, we see a bias-variance trade-off. I think there may be some connection, but I haven’t seen it\nthe idea is we divide the true risk as below\n\\[\n\\mathcal{L}_D(h)=\\epsilon_{app}+\\epsilon_{est}\n\\]\nwhere \\(\\epsilon_{app}=\\min_{h'\\in H}L_D(h')\\) and \\(\\epsilon_{est}=\\mathcal{L}_D(h)-\\epsilon_{app}\\)\n\n\\(\\epsilon_{app}\\), approximation error, it measures how well your hypothesis space is\n\\(\\epsilon_{est}\\), estimation error, it measures how well your learner can estimate the best h (\\(\\in H\\)) using ERM\n\napprox error has nothing to do with how you train with the dataset. if your hypothesis space is well enough (or large enough), it will be small\nest error is on the opposite. It really depends on the learner, sample size so on. It’s similar to the \\(\\epsilon\\) in the definition of agnostic PAC learnability. If your h space is too large (too complicated), then it will need more samples to decrease the est error.\nso, large \\(|H|\\) will reduce approx error, but it may be hard to have a small est error (overfitting), with a high probability a tr set will cause a bad generalization ability\non the contrary, small \\(|H|\\) indeed will give us a small est error but will cause a large approximate error (underfitting)"
  },
  {
    "objectID": "posts/test/example.html",
    "href": "posts/test/example.html",
    "title": "my first post",
    "section": "",
    "text": "This is a test for the \\(\\LaTeX\\) rendering.1\nIt successes with a little effort !!!\nsee Section 1. and Equation 1."
  },
  {
    "objectID": "posts/test/example.html#sec-two",
    "href": "posts/test/example.html#sec-two",
    "title": "my first post",
    "section": "equations and callouts",
    "text": "equations and callouts\nnothing\nEinstein’s theory of special relatively that expresses the equivalence of mass and energy:\n\\[\nE = mc^{2}\n\\tag{1}\\]\n\n\n\n\n\n\nNotemy note\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important."
  },
  {
    "objectID": "posts/test/example.html#cite-at-the-margin",
    "href": "posts/test/example.html#cite-at-the-margin",
    "title": "my first post",
    "section": "cite at the margin",
    "text": "cite at the margin\nColorbars indicate the quantitative extent of image data. Placing in a figure is non-trivial because room needs to be made for them. The simplest case is just attaching a colorbar to each axes:2.\n\n\n2 See the Matplotlib Gallery to explore colorbars further"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-07.html",
    "href": "posts/parallel-algorithm/pa-07.html",
    "title": "parallel algorithm course 07",
    "section": "",
    "text": "tensor core\nmath limited, memory limited"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-07.html#gpu",
    "href": "posts/parallel-algorithm/pa-07.html#gpu",
    "title": "parallel algorithm course 07",
    "section": "GPU",
    "text": "GPU\nL1 caches are independent, L2 caches are shared\nexpected: \\(T_\\text{math}\\ge T_\\text{mem}\\)\n\\[\n\\frac{\\#\\text{opt}}{\\text{math bandwidth}}\\ge \\frac{\\#\\text{bytes}}{\\text{mem bandwidth}}\n\\]\nArithmetic intensity \\(\\frac{\\#\\text{opt}}{\\#\\text{bytes}}\\)\nmath limited when arithmetic intensity \\(\\ge\\frac{\\text{math band}}{\\text{mem band}}\\)"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-07.html#key-ideas",
    "href": "posts/parallel-algorithm/pa-07.html#key-ideas",
    "title": "parallel algorithm course 07",
    "section": "key ideas",
    "text": "key ideas\nsplit, independent ++\nuser cache\nTensor Cores: accelerate dot-product, matrix multiplies, size should better be a mulitple of 128 bits"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-07.html#how-to-do-split",
    "href": "posts/parallel-algorithm/pa-07.html#how-to-do-split",
    "title": "parallel algorithm course 07",
    "section": "how to do split",
    "text": "how to do split\n\nkey: tile\nmultiplication, read a tile at a time to L1 cache\nquantization: size should matches the hardware\nrunning time is stagewise increasing as size increases\nsmall batch \\(\\to\\) low usage of GPU"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-07.html#post-order-reversal",
    "href": "posts/parallel-algorithm/pa-07.html#post-order-reversal",
    "title": "parallel algorithm course 07",
    "section": "post-order reversal",
    "text": "post-order reversal\nDFS, post-order\nhow to parallelize\nhint: list-ranking\n\ntree \\(\\to\\) list, Eular Tour, add points\ninitialization, upward point -1, downward point +1\nlist scan\nlist \\(\\to\\) tree\n\nadjacency list"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-01.html",
    "href": "posts/parallel-algorithm/PA-01.html",
    "title": "parallel algorithm course 01",
    "section": "",
    "text": "gcc -fopenmp\nomp_num_thread(int): request\nmulti-data\nomp_get_thread_num, get id\n\nSMP: equal-time access cost, in theory\nNUMA: different .., practically\n\nFalse Sharing\ncache line\ntwo processors may have access to the same region, repeat many useless write back\n\nSynchronization, to avoid data racing, false sharing (avoid global array) d barrier\n#pragma omp barrier\ncritical\nonly one thread can enter (often cost cheap), mutual exclusion, avoid data racing\n(software support)\n#pragma omp critical\natomic\nonly support (hardware support)\n\nx binopr= expr\nx++, ++x, x–, –x\n\n#pragma omp atomic"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-09.html",
    "href": "posts/parallel-algorithm/pa-09.html",
    "title": "parallel algorithm course 09",
    "section": "",
    "text": "array\nlinked list\ntree (to list)\ngraph (today)\n\nparallel BFS\n\nBFS(G[V,E],S)\n\nD[V] = inf\nD[S] = 0\n\nF = {s}\n\nwhile F not empty do {\n    v = pop(F)\n    for (v, w) in E do {\n        if D[w] = inf {\n            D[w] = D[v] + 1\n            push(F, w)\n        }\n    }\n}\nkey idea: layering \\(F_l\\)\nneed a data structure:\n\nallow repetitive occurance of elements\nunordered\nfast search union and split"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-09.html#parallel-alg",
    "href": "posts/parallel-algorithm/pa-09.html#parallel-alg",
    "title": "parallel algorithm course 09",
    "section": "",
    "text": "array\nlinked list\ntree (to list)\ngraph (today)\n\nparallel BFS\n\nBFS(G[V,E],S)\n\nD[V] = inf\nD[S] = 0\n\nF = {s}\n\nwhile F not empty do {\n    v = pop(F)\n    for (v, w) in E do {\n        if D[w] = inf {\n            D[w] = D[v] + 1\n            push(F, w)\n        }\n    }\n}\nkey idea: layering \\(F_l\\)\nneed a data structure:\n\nallow repetitive occurance of elements\nunordered\nfast search union and split"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-09.html#bag-of-pennats",
    "href": "posts/parallel-algorithm/pa-09.html#bag-of-pennats",
    "title": "parallel algorithm course 09",
    "section": "Bag of pennats",
    "text": "Bag of pennats\n\nA pennant: \\(2^k\\) nodes\nadd an extra root to a balance binary tree\nunion, split\na bag of pennants can be mapped to a binary number\ninsert -&gt; add one (\\(O(\\log n)\\))\ncombine two bags of pennants -&gt; binary number adding (\\(O(\\log n)\\))\nsplit -&gt; require balance (\\(O(\\log n)\\))\n\n\n\n\nbag of pennant\n\n\n// calculate F(l+1) given F(l)\ninitialize(F(l+1), an empty pennant)\n\nfun process-level (G, F(l), F(l+1), D)\nif |F(l)| &gt; threshold {\n    Fa, Fb = split(F(l))\n    spam {\n        process-level (G, Fa, F(l+1), D)\n        process-level (G, Fb, F(l+1), D)\n    }   \n    sync\n} else {\n    foreach v in F(l)\n    par-for (v, w) in E do {\n        if D[w] = inf {\n            D[w] = D[v] + 1\n            insert(F(l+1), w)\n        }\n    }\n}"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-09.html#extend",
    "href": "posts/parallel-algorithm/pa-09.html#extend",
    "title": "parallel algorithm course 09",
    "section": "extend",
    "text": "extend\nmatrix A, B, C\n\\(A\\times B=C\\)\ntile\nconsider \\(A^k\\)\nsave \\(A\\), \\(A^T\\)"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-04.html",
    "href": "posts/parallel-algorithm/pa-04.html",
    "title": "parallel algorithm course 04",
    "section": "",
    "text": "synchronization has costs\nsimple list traversal\ncompute all p in advance"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-04.html#task",
    "href": "posts/parallel-algorithm/pa-04.html#task",
    "title": "parallel algorithm course 04",
    "section": "task",
    "text": "task\n#pragma omp parallel {\n    // not often used\n    #pragma omp task\n    foo();\n\n    #pragma omp barrier\n\n    // more common case\n    #pragma omp single {\n        #pragma omp task\n        bar();\n    }\n}\nexample (with bug)\nint fib(int n) {\n    int x, y; // private\n    if (n &lt; 2) return n;\n\n    #pragma omp task \n    // need `shared(x)`. by default, task copy the whole stack, \n    // x is in different address\n    x = fib(n-1);\n\n    #pragma omp task // need `shared(y)`, default is private in task\n    y = fib(n-2);\n\n    #pragma omp taskwait\n\n    return x+y; // wrong here!!!\n}\n\n#pragma omp parallel single\nfib(n);\ntwo important points\n\nbarrier\ndata env\n\nexample 2 (with bug)\nlist ml;\nElement *e;\n#pragma omp parallel\n#pragma omp single\n{\n    for (e=ml-&gt;first; e; e=e-&gt;next)\n    #pragma omp task // need firstprivate(e)\n        process(e); // has data racing\n}\nreturn to first example\n#pragma omp parallel\n{\n    #pragma omp single\n    {\n        node* p = head;\n        while(p) {\n            #pragma omp task firstprivate(p)\n                process(p);\n            p = p-&gt;next;\n        }\n    }\n}\n\n\n\nrunning schema"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-04.html#merge-sort",
    "href": "posts/parallel-algorithm/pa-04.html#merge-sort",
    "title": "parallel algorithm course 04",
    "section": "merge sort",
    "text": "merge sort\ndirectly using parallel\n\\(T_1=2T_1(\\frac{n}{2})+O(n)=O(n\\cdot log(n)\\)\n\\(T_\\infty=T_\\infty(\\frac{n}{2})+O(n)=O(n)\\)\n\nuse a differernt merge method\nparallel merge\nsay here we have two sorted seqs (\\(\\le\\))\n\\(A=a_1,\\dots,a_n\\) and \\(B=b_1,\\dots,b_n\\)\nlet \\(t=a_{\\lceil \\frac{n}{2}\\rceil}\\), split A and B into sub arr \\(A_1,A_2,B_1,B_2\\) s.t. \\(A_1\\le t, B_1\\le t\\) and \\(A_2\\gt t, B_2\\gt t\\)\nso seq \\(A_1,B_1,A_2,B_2\\) is semi-merged by t, then go on with \\(merge(A_1,B_1)\\) and \\(merge(A_2,B_2)\\)"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-04.html#random-number-generating-problem",
    "href": "posts/parallel-algorithm/pa-04.html#random-number-generating-problem",
    "title": "parallel algorithm course 04",
    "section": "random number generating problem",
    "text": "random number generating problem\n\nproblem\nexample: approximate \\(\\pi\\) using Monto Carlo\nseed(SEED);\n#pragma omp parallel for private(x,y) reduction (+:n_in_circle)\nfor(int i = 0; i &lt; num_trials; i++) {\n    x = random();\n    y = random();\n\n    if (x*x + y*y &lt;= r*r) n_in_circle ++;\n}\n\npi = 4.0 * (1.0 * n_in_circle / num_trials);\n\nLinear Congruential Generator(LCG) (has data racing problem)\nint random_last = 0;\n// need \n// #pragma omp threadprivate(random_last)\n\nint random() {\n    random_next = (MULTIPLIER * random_last + ADDEND) % PMOD;\n    random_last = random_next;\n\n    return random_next;\n}\nparameter: (one possible parameter suite) MULTIPLIER=1366, ADDEND=150889, PMOD=714025\nhas a period (less than PMOD)\n\nsingle thread and multi-thread has different accuracy (multi-thread has poor performance)\ndata racing on var random_last\n\n\nsolution 1\nadd #pragma omp threadprivate(random_last) under int random_last=0\nhas a local copy of random_last when creating a thread\nsimilar to firstprivate\nproblem: still poor than single thread version\ndifferent random range in threads maybe overlap\n\n\nsolution 2\nLeap Frog method\ngenerate different seeds for each thread\nsituation for ADDEND=0\n#pragma omp single\n{\n    nthreads = ...\n    iseed = PMOD / MULTIPLIER;\n    pseed[0] = iseed;\n    mult_n = MULTIPLIER;\n    for (int i = 0; i &lt; nthreads; i++) {\n        iseed = (unsigned long long) ((MULTIPLIER * iseed) % PMOD);\n        pseed[i] = iseed;\n        mult_n = (mult_n * MULTIPLIER) % PMOD;\n    }\n    id = ...\n    random_last = (unsigned long long) pseed[id];\n}"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html",
    "href": "posts/parallel-algorithm/solution.html",
    "title": "midterm exam",
    "section": "",
    "text": "work complexity 是当处理器个数为 1 时，完成算法所需的基础操作的个数。span complexity 是在数据依赖 DAG 图中的最长路径的时间复杂度，即当处理器个数为 \\(\\infty\\) 时，基础操作的个数。\n\n\n\nBrent’s Theorem:\n\\[\n\\max\\left\\{T_\\infty,\\frac{T_1}{p}\\right\\} \\le T_p \\le \\frac{T_1-T_\\infty}{p} + T_\\infty.\n\\]\nProof: 左侧不等式显然。\n对于右侧不等式，\n对 DAG 图进行分层，记第 \\(i\\) 层的操作数为 \\(m_i\\)，共 \\(n\\) 层，则有 \\[\nT_1=\\sum_{i=1}^n m_i\n\\]\n对第 \\(i\\) 层进行并行，由于这 \\(m_i\\) 个操作独立，所以\n\\[\nT_p^i=\\left \\lceil \\frac{m_i}{p} \\right \\rceil \\le \\frac{m_i-1}{p} + 1.\n\\]\n故\n\\[\nT_p=\\sum_{i=1}^{n}T_p^i\\le \\sum_{i=1}^{n}\\left ( \\frac{m_i-1}{p}+1\\right)=\\frac{T_1-T_\\infty}{p} + T_\\infty\\blacksquare\n\\]\n\n\n\n\n可结合性即，\\(\\forall a,b,c\\)，有 \\(\\text{oper}(\\text{oper}(a,b),c)=\\text{oper}(a, \\text{oper}(b,c))\\)。\n由于并行程序在 scheduling 时，每个 task 的开始时间和运行时间我们无法预知，对于一系列的操作无法保证运算的顺序，从而保证正确性。若操作满足可结合性，我们可以使用 merge 等算法保证操作数顺序的同时进行并行处理；若操作又满足可交换性，则可以简单的使用 par-for 等进行并行，且能保证正确性。\n\n\n\n\ndifference\n\nscan 操作的对象是一个数组，每一个位置的答案所对应的依赖元素是 predefined。list ranking 操作对象是 linked list 或 array pool，每个位置的答案所依赖的元素是未知的，必须经过某种串行的查找来得到对应的依赖关系。\nscan 计算的是 \\(a_i=\\bigoplus_{k=1}^i\\text{arr}_k\\)，list ranking 计算的是每个 element 的 ranking，其中 \\(\\bigoplus\\) 是可结合、可交换的二元运算。\nlist ranking 使用 jump 的思想来解决，而 scan 没有。\n\nin common\n\n两种算法解决的问题都是 \\(n\\to n\\)。\n\n\n\n\n\ndifference\n\nquicksort 只进行一次采样，选择一个 pivot element，将数组分成两段，而 samplesort 会进行 \\(k\\cdot (p-1)\\) 次采样，选出 p-1 个 pivot element，将数组分成 p 段。\n\nin common\n\n都是基于 divide and conquer 思想，解决 sorting 问题"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html#algorithm-1",
    "href": "posts/parallel-algorithm/solution.html#algorithm-1",
    "title": "midterm exam",
    "section": "",
    "text": "work complexity 是当处理器个数为 1 时，完成算法所需的基础操作的个数。span complexity 是在数据依赖 DAG 图中的最长路径的时间复杂度，即当处理器个数为 \\(\\infty\\) 时，基础操作的个数。\n\n\n\nBrent’s Theorem:\n\\[\n\\max\\left\\{T_\\infty,\\frac{T_1}{p}\\right\\} \\le T_p \\le \\frac{T_1-T_\\infty}{p} + T_\\infty.\n\\]\nProof: 左侧不等式显然。\n对于右侧不等式，\n对 DAG 图进行分层，记第 \\(i\\) 层的操作数为 \\(m_i\\)，共 \\(n\\) 层，则有 \\[\nT_1=\\sum_{i=1}^n m_i\n\\]\n对第 \\(i\\) 层进行并行，由于这 \\(m_i\\) 个操作独立，所以\n\\[\nT_p^i=\\left \\lceil \\frac{m_i}{p} \\right \\rceil \\le \\frac{m_i-1}{p} + 1.\n\\]\n故\n\\[\nT_p=\\sum_{i=1}^{n}T_p^i\\le \\sum_{i=1}^{n}\\left ( \\frac{m_i-1}{p}+1\\right)=\\frac{T_1-T_\\infty}{p} + T_\\infty\\blacksquare\n\\]\n\n\n\n\n可结合性即，\\(\\forall a,b,c\\)，有 \\(\\text{oper}(\\text{oper}(a,b),c)=\\text{oper}(a, \\text{oper}(b,c))\\)。\n由于并行程序在 scheduling 时，每个 task 的开始时间和运行时间我们无法预知，对于一系列的操作无法保证运算的顺序，从而保证正确性。若操作满足可结合性，我们可以使用 merge 等算法保证操作数顺序的同时进行并行处理；若操作又满足可交换性，则可以简单的使用 par-for 等进行并行，且能保证正确性。\n\n\n\n\ndifference\n\nscan 操作的对象是一个数组，每一个位置的答案所对应的依赖元素是 predefined。list ranking 操作对象是 linked list 或 array pool，每个位置的答案所依赖的元素是未知的，必须经过某种串行的查找来得到对应的依赖关系。\nscan 计算的是 \\(a_i=\\bigoplus_{k=1}^i\\text{arr}_k\\)，list ranking 计算的是每个 element 的 ranking，其中 \\(\\bigoplus\\) 是可结合、可交换的二元运算。\nlist ranking 使用 jump 的思想来解决，而 scan 没有。\n\nin common\n\n两种算法解决的问题都是 \\(n\\to n\\)。\n\n\n\n\n\ndifference\n\nquicksort 只进行一次采样，选择一个 pivot element，将数组分成两段，而 samplesort 会进行 \\(k\\cdot (p-1)\\) 次采样，选出 p-1 个 pivot element，将数组分成 p 段。\n\nin common\n\n都是基于 divide and conquer 思想，解决 sorting 问题"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html#openmp-1",
    "href": "posts/parallel-algorithm/solution.html#openmp-1",
    "title": "midterm exam",
    "section": "OpenMP 1",
    "text": "OpenMP 1\n\nQ6 False sharing and how to avoid\n\n由于 cache 的存在，在一个 cpu 上的 cache 中可能会有其他 cpu 所处理的与当前 cpu 无关的数据 (一般是数组元素)，当那一部分的数据发生更改时，当前处理器的 cache 需要进行同步，从而进行一系列的没有意义的 IO 操作，从而严重影响并行性能。\n避免 false sharing\n\n对于数组，我们可以通过增加 padding，强制将不同 cpu cache 里的元素隔离开。\n避免使用全局数组，对每个 task 使用 private 的数组，使用 synchronization pragma 来进行同步。\n\n\n\n\nQ7 Why do synchronizations slow down your program\n\n若有很多线程同时需要进行同步操作，进入排队等待状态，那么此时并行退化成了串行，会造成性能的下降。\n同步操作本身会有一定的开销，如排队调度、处理器之间的通信等。\n\n\n\nQ8 When should we use critical, atomic or lock pragma\n\ncritical: 当需要避免 data racing，只允许一个线程进入，而且关键区计算的开销不是非常大的时候使用。\natomic: 只能在一些简单的运算上使用(需要硬件支持)，如 a++ 等。\nlock: 当需要更复杂的同步或有复杂的锁的关系时使用。\n\n\n\nQ9 Give four reasons why the iterations are not in a static order for a parallel for loop\n\nparallel for 的 schedule 参数默认是 static，即在循环开始前为每个 thread 分配大致等量个 iterations1。因此，由于不同 thread 执行的 iterations chuncks 之间在运行时是独立的，它们执行的顺序是不确定的。\n程序的运行会因为 cpu 的调度等原因，导致运行的时间不固定。从而影响执行的顺序。\n计算机并不能保证提供固定数量的 cpu，因此 OpenMP 对并行 tasks 的调度和管理也不固定。\n由于 OpenMP 和操作系统的调度，threads 的执行顺序并不一定是他们的创建顺序，且不固定。\n\n1 Openmp.org. [Online]. Available: https://www.openmp.org/wp-content/uploads/OpenMP-API-Specification-5-1.pdf. [Accessed: 22-Apr-2022].\n\n\n\n\n\nNotesolution\n\n\n\n(Compile, Run) \\(\\times\\) (Hardware, Software)\n\n\n\n\nQ10 Safe way to generate random numbers in parallel\n使用并行版 LCG 算法生成随机数。\n\n// 原 LCG 算法\nint random() {\n    random_next = (MULTIPLIER * random_last + ADDEND) % PMOD;\n    random_last = random_next;\n\n    return random_next;\n}\n\n在原 LCG 算法基础上，使用 Leap Frog Method。记由 LCG 算法生成的随机数序列为 \\(a_0,a_1,\\dots\\)，有 k 个 thread。取 \\(a_0,a_1,\\dots,a_{k-1}\\) 作为每个 thread 随机数序列的种子，并修改 MULTIPLIER 和 ADDEND，使得 \\(\\text{next}(a_i)=a_{i+k}\\)，即每个 thread \\(t\\) 所使用的随机数序列为 \\(a_{t::k}\\)。"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html#algorithm-2-comment-deletion",
    "href": "posts/parallel-algorithm/solution.html#algorithm-2-comment-deletion",
    "title": "midterm exam",
    "section": "Algorithm 2: comment deletion",
    "text": "Algorithm 2: comment deletion\nsolution: scan, fragsum"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html#algorithm-3-missing-element",
    "href": "posts/parallel-algorithm/solution.html#algorithm-3-missing-element",
    "title": "midterm exam",
    "section": "Algorithm 3: missing element",
    "text": "Algorithm 3: missing element\nsolution: xor"
  },
  {
    "objectID": "posts/parallel-algorithm/solution.html#algorithm-4-knn",
    "href": "posts/parallel-algorithm/solution.html#algorithm-4-knn",
    "title": "midterm exam",
    "section": "Algorithm 4: KNN",
    "text": "Algorithm 4: KNN\nsolution:\nfor i: 0 to N\n    for j: i+1 to N\n        d[i,j]=dis[A[i],A[j]] // heap[i].add, heap[j].add, lock\ndesigned schedule to balance work flow in each thread\nlock"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-10.html",
    "href": "posts/parallel-algorithm/pa-10.html",
    "title": "parallel algorithm course 10",
    "section": "",
    "text": "final exam\nreview\n\nfundamental\n\n\nDAG\nwork-span analysis\n\nideal: \\(T_1(n)=T_s(n)\\), \\(T_\\infty(n)=\\Theta(\\log^k(n))\\)\n\nonly consider shared data memory model\n\nalgorithm：\n\nmap: n-&gt;n\n\nassociative\n\nreduce:n -&gt; 1\nscan: n -&gt; n\n\ncompact: n -&gt; m\n\nlist ranking: n -&gt; n, input becomes linked list, GRAPH, BFS, DFS, find independent\nsorting, sample sort\n\ngoal:\n\noptimal complexity\nindependent ++, sync –, don’t use sync too much, has cost, e.g. print message during parallel\ne.g. histgram, lock in each bucket\nsymetrics –, repeat occurance, break symetric, use randomize\n\nthinking:\n\ncase to general\nforward - backward, cover gap between input and output\nbit-wise, radix sort\nmatrix-wise, compute fibonacci sequence, matrix operation\n\npattern\n\ndivide & conquer\nindep set\nrandom\njump\nEulur tour\nBag of pennants (conform divide and conquer patterm)\n\n\nopenacc\nprofile driven programming\n\nanalyse\nparallel\noptimize\n\nincremental programming\nCPU -&gt; GPU -&gt; Unified memory -&gt; data parallel -&gt; loop -&gt; blocking\nblocking:\n\nIO and compute parallel\nmulti-device\n\n\nAnalyse\n\nobserve profile\nbottle-neck, for loop\nimprove \\(\\frac{\\text{compute}}{\\text{mem}}\\) access ratio\n\nParallel\n\nalgorithm\n\nOptimize\n\ndata movement, manual management\nlarge matrix, sometimes we don’t need load all the elements\nloop mapping: tell compile how loop maps the level of parallel, e.g. vetor length\nvector 32*n -&gt; n warps\nblocking, 流水线并行\n\ninput compute output\ncompute -&gt; futher split -&gt; multi device\n\ntile &lt;- GPU 2-level cache usage\ncollapse\nmemory access pattern, keep continuous access\n\nGPU hardware\n\n\n\nSMP\n\n\n\n\n简答题 X 2\n算法题\n\n期中前 X 1\n期中后 X 1\n\n编程题 X 1"
  },
  {
    "objectID": "posts/tools/tc.html",
    "href": "posts/tools/tc.html",
    "title": "Total Commander Tips",
    "section": "",
    "text": "xbeta blog about TC\nA famous introductory blog to Total Commander.\nTotal Commander is a powerful customizable file manager tool. It has enormous features that are totally beyond one’s imagination.\nHere is a quick note while learning the operation of TC from the blog1."
  },
  {
    "objectID": "posts/tools/tc.html#config-files",
    "href": "posts/tools/tc.html#config-files",
    "title": "Total Commander Tips",
    "section": "Config files",
    "text": "Config files\n.ini config file is recommended to be put under the installation directory.\nFor better management.\nAlso set UseIniInProgramDir=7, ignore register file.\nxbeta’s config file for learning."
  },
  {
    "objectID": "posts/tools/tc.html#location-and-selection",
    "href": "posts/tools/tc.html#location-and-selection",
    "title": "Total Commander Tips",
    "section": "location and selection",
    "text": "location and selection\n\ndirectory hotlist\nCtrl+d x\n\nhotlist = most used directorys\nextremely fast to navigate\n\n\n\n\n\n\n\nTip\n\n\n\n\nuse subdirectory in hotlist\ntidy up the hotlist periodically, e.g., make a Ctrl+d n (now) sublist for most frequent dirs recently.\n\n\n\n\n\nchange disk\nAlt+F1 for left panel, Alt+F2 for right panel\n\n\ncommon way of changing dir\n\nEnter or Backspace\nCtrl+\\ to root dir\n\n\n\nquick search\nmy config:\nConfiguration -&gt; Quick Search\n\ntick Letters only\nuncheck Beginning (...)\ncheck Ending (...)\n\n\n\nHistory\nAlt+↓\n\n\nSorting\nSort with multiple keys.\nE.g.,\n\nFirst click Ext\nThen, click Date, Name while pressing Ctrl\n\n\n\nFiltering\nShow only the desired files\nShow -&gt; Custom...\n\n\nColoring\nConfiguration -&gt; Color -&gt; Define colors by file type...\n\n2days as red\nexe as purple\n7days as blue\n\n\n\nSelecting\nRecommend to use the default NC mode (right single click to select)\n\nConfiguration -&gt; Operation\n\nLong right press for right menu.\n\n\nmultiple selection\n\nAlt+'+' ('+' in the numeric keypad of keyboard): also select files with the same extension (you have already been selecting a file)\n* (also in the numeric keypad): reverse selection\n+ and -: also select or unselect some files (pops up a window for you to choose)\nInsert for a single selection, function like right single click and then ↓.\n\n\n\n\nBranch View\nCtrl+b: show all files in current and sub- directories."
  },
  {
    "objectID": "posts/tools/tc.html#pack-unpack",
    "href": "posts/tools/tc.html#pack-unpack",
    "title": "Total Commander Tips",
    "section": "Pack / Unpack",
    "text": "Pack / Unpack\nPack:\n\nAlt+F5 / Ctrl+Alt+F5\nTo save the archive in the current dir, set CA+F5=cm_PackFiles in [Shortcuts] session of wincmd.ini file. Ctrl+Alt+F5\n\nUnpack:\n\nAlt+F9, then clear the input field (empty means current folder)\ncheck Unpack each archive ... to save in a subfolder\n\n\n\n\n\n\n\nTip\n\n\n\nto make it a default manner (save in a subfolder instead of current folder), set UnZIPSeperateSubdirs=-2 in [Packer] section of wincmd.ini.\n\n\nBrowsing packed file:\n\nbrowse like a normal folder\nCtrl + → or Ctrl + ← or Ctrl + PageDown: open in right/left/current panel"
  },
  {
    "objectID": "posts/tools/tc.html#rename",
    "href": "posts/tools/tc.html#rename",
    "title": "Total Commander Tips",
    "section": "rename",
    "text": "rename\nShift+F6 is the default (change filename), press again to include extension\nuse F2 is recommended.\nadd F2=cm_RenameOnly in [Shortcuts] section"
  },
  {
    "objectID": "posts/tools/tc.html#addons",
    "href": "posts/tools/tc.html#addons",
    "title": "Total Commander Tips",
    "section": "Addons",
    "text": "Addons\n\nxbeta plugin collections\nofficial addon collections\n\n\nmy config file, mod a little from xbeta\nfor more details and usage, please refer to the xbeta blog or F1 help manual."
  },
  {
    "objectID": "posts/programming/pytorch-notes.html",
    "href": "posts/programming/pytorch-notes.html",
    "title": "PyTorch Notes",
    "section": "",
    "text": "x.numel() number of elements in x\nbroadcast mechanism\nY = Y + X would allocate a new space for the result of Y + X. Y then is the reference to this new memory. Y += X or Y[:] = Y + X is better. (id(Y) will be unchanged.)\nfloat() or int() converts a scalar tensor to a standard number, similar to x.item()\nA * B element-wise product.\nA_sum = A.sum(axis=1, keepdims=True) will keep the number of axis. A / A_sum will enable broadcast mechanism.\nA.cumsum(axis=0) accumulated sum.\nlinear algebra (matrix, vector) multiplication\n\ndot product: torch.dot(x, y) only accept 1-D tensor.\nmatrix-vector multiplication: torch.mv(A, x) matrix and vector. x is 1-D vector. All in column vectors.\nmatrix-matrix multiplication: torch.mm(A, B).\n\ntorch.distributions\n\nmultinomial.Multinomial(n, probs).sample(N, )"
  },
  {
    "objectID": "posts/programming/pytorch-notes.html#gadget-functions-torch",
    "href": "posts/programming/pytorch-notes.html#gadget-functions-torch",
    "title": "PyTorch Notes",
    "section": "",
    "text": "x.numel() number of elements in x\nbroadcast mechanism\nY = Y + X would allocate a new space for the result of Y + X. Y then is the reference to this new memory. Y += X or Y[:] = Y + X is better. (id(Y) will be unchanged.)\nfloat() or int() converts a scalar tensor to a standard number, similar to x.item()\nA * B element-wise product.\nA_sum = A.sum(axis=1, keepdims=True) will keep the number of axis. A / A_sum will enable broadcast mechanism.\nA.cumsum(axis=0) accumulated sum.\nlinear algebra (matrix, vector) multiplication\n\ndot product: torch.dot(x, y) only accept 1-D tensor.\nmatrix-vector multiplication: torch.mv(A, x) matrix and vector. x is 1-D vector. All in column vectors.\nmatrix-matrix multiplication: torch.mm(A, B).\n\ntorch.distributions\n\nmultinomial.Multinomial(n, probs).sample(N, )"
  },
  {
    "objectID": "posts/programming/pytorch-notes.html#gadget-functions-pandas",
    "href": "posts/programming/pytorch-notes.html#gadget-functions-pandas",
    "title": "PyTorch Notes",
    "section": "gadget functions (pandas)",
    "text": "gadget functions (pandas)\n\ndata.fillna(data.mean())\npd.get_dummies(data, dummy_na=True) Convert categorical variable into dummy/indicator variables. Works for str."
  },
  {
    "objectID": "posts/programming/pytorch-notes.html#gadget-functions-d2l",
    "href": "posts/programming/pytorch-notes.html#gadget-functions-d2l",
    "title": "PyTorch Notes",
    "section": "gadget functions (d2l)",
    "text": "gadget functions (d2l)\n\nd2l.plot example\n\nx = np.arange(0, 3, 0.1) d2l.plot(x, [x ** 2, 2 * x - 1], 'x', 'f(x)', legend=['f(x)', 'Tangent'])"
  },
  {
    "objectID": "posts/programming/pytorch-notes.html#plot",
    "href": "posts/programming/pytorch-notes.html#plot",
    "title": "PyTorch Notes",
    "section": "plot",
    "text": "plot\n\nexample\n\nplt.plot(y, label=(\"label\"))\nplt.axhline(y=0, color='black', linestyle='dashed')\nplt.gca().set_xlabel('x label')\nplt.gca().set_ylabel('y label')\nplt.legend()"
  },
  {
    "objectID": "posts/paper-reading/24-02-29-zhang2024batchicl.html",
    "href": "posts/paper-reading/24-02-29-zhang2024batchicl.html",
    "title": "reading notes on paper Batch-ICL Effective, Efficient, and Order-Agnostic In-Context Learning by Zhang et al.",
    "section": "",
    "text": "link to arXiv\nAbstract"
  },
  {
    "objectID": "posts/paper-reading/24-02-29-zhang2024batchicl.html#summary",
    "href": "posts/paper-reading/24-02-29-zhang2024batchicl.html#summary",
    "title": "reading notes on paper Batch-ICL Effective, Efficient, and Order-Agnostic In-Context Learning by Zhang et al.",
    "section": "Summary",
    "text": "Summary\nThis paper aims to resolve the order-instability problem in ICL. The basic idea is to treat each ICL example seperately and then aggregate the latent from each ICL in another Transformer layer. The main idea is from the prevelant view of ICL as a meta-optimization process.\n\n\n\nmain idea"
  },
  {
    "objectID": "posts/paper-reading/24-02-29-zhang2024batchicl.html#my-thoughts",
    "href": "posts/paper-reading/24-02-29-zhang2024batchicl.html#my-thoughts",
    "title": "reading notes on paper Batch-ICL Effective, Efficient, and Order-Agnostic In-Context Learning by Zhang et al.",
    "section": "My thoughts",
    "text": "My thoughts\nThis paper may be under review in ACL’24 or counterpart. Many papers from ACL or EMNLP seem to be not well-informed about the related work. It’s hard to scrasp the novelty of those papers when some (or even many) of the related work are not mentioned.\nThe explanation of the order-instability problem from the perspective of order-dependent meta-optimization process (approximate to GD of some linear model) seems promising. If the proposed algorithm is illustrated in the attention mask matarix, it may be more clearer. I think it is not fundamentally different from just using block-diagonal causal attention mask matrix for each example.\nSGD is order dependent and the instability is from the variance of the gradient estimation from a single sample. Mini-batch will reduce the variance and improve the convergence rate of SGD. But they should behave similar at the end of the iteration under some mild conditions. More analysis on the convergence may be a more direct way of resolving the order-instability problem in ICL.\nAn important reference (I think) missing in the related work is the paper by Ding et al. [1] which has been accepted in ICLR’24. They say that CausalLM may not convergent to the desired solution for ICL (the stationary point is not optimal) while PrefixLM can converge to the least square solution stationary point. Therefore some fundamental limitations of CausalLM on ICL have already been discussed.\nMoreover, the paper by Bhatia et al. [2] which is accepted by NeurIPS’23 seems to be a little similar to this paper except that they do the aggregation using a BERT with one single step instead of doing on \\(K\\) layers."
  },
  {
    "objectID": "posts/paper-reading/24-02-29-zhang2024batchicl.html#references",
    "href": "posts/paper-reading/24-02-29-zhang2024batchicl.html#references",
    "title": "reading notes on paper Batch-ICL Effective, Efficient, and Order-Agnostic In-Context Learning by Zhang et al.",
    "section": "References",
    "text": "References\n[1] N. Ding, T. Levinboim, J. Wu, S. Goodman, and R. Soricut, “CausalLM is not optimal for in-context learning.” arXiv, Sep. 02, 2023. Accessed: Nov. 22, 2023. [Online]. Available: http://arxiv.org/abs/2308.06912\n[2] K. Bhatia, A. Narayan, C. De Sa, and C. Ré, “TART: A plug-and-play Transformer module for task-agnostic reasoning,” arXiv.org. Accessed: Jun. 20, 2023. [Online]. Available: https://arxiv.org/abs/2306.07536v1"
  },
  {
    "objectID": "posts/esl/ESL-02.html",
    "href": "posts/esl/ESL-02.html",
    "title": "unsupervised model related",
    "section": "",
    "text": "quick notes while reading unsupervised model related part in ESL"
  },
  {
    "objectID": "posts/esl/ESL-02.html#knn",
    "href": "posts/esl/ESL-02.html#knn",
    "title": "unsupervised model related",
    "section": "KNN:",
    "text": "KNN:\n\ntangent distance\nInvariant Metrics and Tangent Distance (Simard et al., 1993)"
  },
  {
    "objectID": "posts/esl/ESL-02.html#k-means",
    "href": "posts/esl/ESL-02.html#k-means",
    "title": "unsupervised model related",
    "section": "K-means:",
    "text": "K-means:\n\nfind clusters,\nrecompute the cluster centers\n\n\nK-means for classification\n\napply K-means for each class, using R prototypes per class (K in total)\nassign a label for each prototypes (K x R in total)\nclassify new x to the nearest prototype"
  },
  {
    "objectID": "posts/esl/ESL-02.html#learning-vector-quantization",
    "href": "posts/esl/ESL-02.html#learning-vector-quantization",
    "title": "unsupervised model related",
    "section": "Learning Vector Quantization",
    "text": "Learning Vector Quantization\n\ncons of vanilla K-means classification:\n\nother samples of different class won’t involve in the position of other class\n\nfor a random training sample, move the closest prototype a bit (towards or away)"
  },
  {
    "objectID": "posts/esl/ESL-02.html#gaussian-mixture",
    "href": "posts/esl/ESL-02.html#gaussian-mixture",
    "title": "unsupervised model related",
    "section": "Gaussian mixture",
    "text": "Gaussian mixture\n\nassign weight for each cluster (gaussian density)"
  },
  {
    "objectID": "posts/esl/ESL-02.html#discriminant-adaptive-nearest-neighbor-dann",
    "href": "posts/esl/ESL-02.html#discriminant-adaptive-nearest-neighbor-dann",
    "title": "unsupervised model related",
    "section": "discriminant adaptive nearest-neighbor (DANN)",
    "text": "discriminant adaptive nearest-neighbor (DANN)\n\n\\(\\varSigma=W^{-1/2}[B^*+\\epsilon I]W^{-1/2}\\)\n\\(\\varSigma^{1/2} (x-x_0)=\\textrm{circle}\\)\n\\(W\\) normalization, spheres the data\n\\(B\\) stretch, assign larger weights to the directions with larger covariance."
  },
  {
    "objectID": "posts/esl/ESL-02.html#market-basket-analysis",
    "href": "posts/esl/ESL-02.html#market-basket-analysis",
    "title": "unsupervised model related",
    "section": "Market Basket Analysis",
    "text": "Market Basket Analysis\n\nThe Apriori Algorithm\ndiscover association rules with high support values and confidence"
  },
  {
    "objectID": "posts/esl/ESL-02.html#unsupervised-as-supervised-learning",
    "href": "posts/esl/ESL-02.html#unsupervised-as-supervised-learning",
    "title": "unsupervised model related",
    "section": "Unsupervised as Supervised Learning",
    "text": "Unsupervised as Supervised Learning\n\nreference density function"
  },
  {
    "objectID": "posts/esl/ESL-02.html#generalized-association-rules-not-understand",
    "href": "posts/esl/ESL-02.html#generalized-association-rules-not-understand",
    "title": "unsupervised model related",
    "section": "Generalized Association Rules (NOT UNDERSTAND)",
    "text": "Generalized Association Rules (NOT UNDERSTAND)"
  },
  {
    "objectID": "posts/esl/ESL-02.html#clustering-analysis",
    "href": "posts/esl/ESL-02.html#clustering-analysis",
    "title": "unsupervised model related",
    "section": "Clustering Analysis",
    "text": "Clustering Analysis\n\nDissimilarity Based on Attributes (dissimilarity defined individually on each attributes)\n\nQuantitative variables:\n\n\\(\\ell(\\textrm{abs}(x_i-x_j))\\) \\(\\rightarrow\\) squared-error loss, identity (just \\(\\textrm{abs}\\))\n\n\n\n\ncorreltation\n\nOrdinal variables\nCategorical variables\n\n\n\nObject Dissimilarity (combining the p-individual attribute dissimilarities)\n\nweighted average"
  },
  {
    "objectID": "posts/probability/concentration.html",
    "href": "posts/probability/concentration.html",
    "title": "notes on some concentration inequalities",
    "section": "",
    "text": "the goal is to seek for an upperbound for the tail distribution, usually of the form\n\\[\nP\\{Z-\\mathbb{E}Z\\ge t\\}\n\\]\nwhere \\(t\\gt 0\\).\n\nMarkov’s inequality\n\n\\[\nP\\{Y\\ge t\\}\\le P\\{\\Phi(Y)\\ge \\Phi(t)\\} \\le \\frac{\\mathbb{E}\\Phi(Y)}{\\Phi(t)}\n\\]\nwhere \\(\\Phi(\\cdot)\\) is a nondecreasing and nonnegative function.\n\nChebyshev’s inequality\n\nreplace \\(Y\\) with \\(|Z-\\mathbb{E}Z|\\) and taking \\(\\Phi(t)=t^2\\),\n\\[\nP\\{|Z-\\mathbb{E}Z|\\ge t\\}\\le \\frac{Var{Z}}{t^2}\n\\]\nmore generally, use \\(t^q\\), and choose an optimal \\(q\\)\n\nCramer-Chernoff method\n\n\\[\nP\\{Z\\ge t\\}\\le e^{-\\lambda t}\\mathbb{E}e^{\\lambda Z},\n\\]\nwhere \\(\\lambda\\ge0\\)\nchoose exponential family fn as \\(\\Phi(\\cdot)\\)\nChebyshev’s is sharper (generalized version, with optimal \\(q\\)), but Chernoff’s is more often used, mainly because the expectation of product decomposition property of sum of independent random vars.\n\nCramer-Chernoff method\nlogarithm of the MGF \\(\\Psi_Z(\\lambda)=\\log \\mathbb{E}e^{\\lambda Z}\\)\nwe would like to minimize the right hand side of the inequality, which equivalently is to minimize the Cramer tranformer of Z,\n\\[\n\\Psi_Z^*(t)=\\sup_{\\lambda \\le 0}(\\lambda t-\\Psi_Z(\\lambda))\n\\]\nif we allow \\(\\lambda\\) to be in \\(\\mathbb{R}\\), then it conincides with Fenchel-Lengedre dual.\n\n\n\n\n\n\nNoteproperties\n\n\n\n\nconvexity of log-MGF (using Holder’s inequality)\n\\(\\Psi_Z(\\lambda)\\ge \\lambda \\mathbb{E}Z\\) (using Jensen’s inequality)\nif \\(\\Psi_Z(\\lambda)\\) is differentiable, then \\(\\lambda_t\\) (optimal \\(\\lambda\\)) is \\((\\Psi_Z')^{-1}(t)\\) (strict convexity -&gt; increasing derivative)"
  },
  {
    "objectID": "diary.html",
    "href": "diary.html",
    "title": "Diary",
    "section": "",
    "text": "Date\n\n\n\nTitle\n\n\n\nCategories\n\n\n\n\n\n\n\n\nOct 5, 2024\n\n\nmemorial\n\n\npaper-list, memorial\n\n\n\n\n\n\nMar 18, 2024\n\n\nModelGPT - a recent work actively reaching out for collaboration\n\n\npaper-list\n\n\n\n\n\n\nMar 10, 2024\n\n\nGeLore\n\n\npaper-list\n\n\n\n\n\n\nApr 2, 2022\n\n\nInequality\n\n\ninequality\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shiguang WU",
    "section": "",
    "text": "I’m a M.Sc student at IRLab of Shandong University, supervised by Prof. Pengjie Ren and Prof. Zhaochun Ren. I received my B.E. from Taishan College, Shandong University in 2023.\nI’m interested in (theoretical, analytical) information retrieval, especially in generative retrieval, embedding models, and recommender systems.\nPlease feel free to contact me at furyton AT outlook DOT com."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Shiguang WU",
    "section": "EDUCATION",
    "text": "EDUCATION\nM.Sc., Shandong University Information Retrieval Lab Sep 2023 — Jun 2026 (expected)\n\nSupervised by Prof. Pengjie Ren and Prof. Zhaochun Ren\n\nB.Sc., Shandong University Taishan College Sep 2019 — Jun 2023\n\nGPA: 92.44/100 (ranking 2/17)"
  },
  {
    "objectID": "index.html#research-experience",
    "href": "index.html#research-experience",
    "title": "Shiguang WU",
    "section": "RESEARCH EXPERIENCE",
    "text": "RESEARCH EXPERIENCE\nInternship Tencent WeChat Feb 2025 — Present\n\nSupervised by Dr. Hongyu Lu.\n\nUndergraduate Research Assistant Information Retrieval Lab Sep 2021 — Jun 2023\n\nSupervised by Prof. Xin Xin and Prof. Zhaochun Ren"
  },
  {
    "objectID": "index.html#publications",
    "href": "index.html#publications",
    "title": "Shiguang WU",
    "section": "PUBLICATIONS",
    "text": "PUBLICATIONS\n\n\n[2025] Shiguang Wu, Zhaochun Ren, Xin Xin, Jiyuan Yang, Mengqi Zhang, Zhumin Chen, Maarten de Rijke, and Pengjie Ren, Constrained auto-regressive decoding constrains generative retrieval. Proceedings of the 48th international ACM SIGIR conference on research and development in information retrieval 2429–2440.\n\n\n[2025] Wenhao Zhang, Mengqi Zhang, Shiguang Wu, Jiahuan Pei, Zhaochun Ren, Maarten de Rijke, Zhumin Chen, and Pengjie Ren, ExcluIR: Exclusionary neural information retrieval. Proceedings of the AAAI Conference on Artificial Intelligence. 39, 13295–13303.\n\n\n[2024] Shiguang Wu, Xin Xin, Pengjie Ren, Zhumin Chen, Jun Ma, Maarten de Rijke, and Zhaochun Ren, Learning robust sequential recommenders through confident soft labels. ACM Trans. Inf. Syst. 43.\n\n\n[2024] Pengjie Ren, Chengshun Shi, Shiguang Wu, Mengqi Zhang, Zhaochun Ren, Maarten de Rijke, Zhumin Chen, and Jiahuan Pei, Mini-ensemble low-rank adapters for parameter-efficient fine-tuning. Proceedings of the 62nd annual meeting of the association for computational linguistics (volume 1: Long papers).\n\n\n[2024] Shiguang Wu, Wenda Wei, Mengqi Zhang, Zhumin Chen, Jun Ma, Zhaochun Ren, Maarten de Rijke, and Pengjie Ren, Generative retrieval as multi-vector dense retrieval. Proceedings of the 47th international ACM SIGIR conference on research and development in information retrieval. Best Paper Honorable Mention Award."
  },
  {
    "objectID": "index.html#academic-services",
    "href": "index.html#academic-services",
    "title": "Shiguang WU",
    "section": "ACADEMIC SERVICES",
    "text": "ACADEMIC SERVICES\nReviewer: Information Processing & Management (IP&M)\nPC Member: AAAI’26, SIGIR’24, SIGIR-AP’25, WSDM’26, WWW’26"
  },
  {
    "objectID": "index.html#awards-and-achievements",
    "href": "index.html#awards-and-achievements",
    "title": "Shiguang WU",
    "section": "AWARDS AND ACHIEVEMENTS",
    "text": "AWARDS AND ACHIEVEMENTS\n\nNational Outstanding Student Scholarship. China. 2022, 2024, 2025.\nBest Paper Honorable Mention. SIGIR. 2024.\nOutstanding Undergraduate Thesis Award. Shandong University. 2023.\nOutstanding Student Scholarship. Shandong University. 2020 — 2022.\n\n\n\nThe 18th Certified Sofware Professional Examination. Top 2.65%. 2020."
  },
  {
    "objectID": "posts/esl/ESL-01.html",
    "href": "posts/esl/ESL-01.html",
    "title": "The elements of statistical learning 01",
    "section": "",
    "text": "committee from a bunch of weak learners\\(G_m\\)(slightly better than rand)\n\\[\nG(x)=sign\\left(\\sum_{m=1}^Ma_mG_m(x)\\right)\n\\]\none generic method is forward-stagewise method where you compute one model \\(G_m\\) and its correspd weight \\(a_m\\) at a time (min \\(L(y_i, f_m(x_i)+\\beta G_m(x_i))\\)).\nif using MSE as the \\(L\\) loss, each time we are seeking for a model \\(\\beta G\\) that fit the residual.\n\n\niteratively fit \\(G_m\\) on a weighted dataset.\nmethod derived by using exp loss instead of the common mse ..\n\\[e^{-y_if(x_i)}\\]\nsuppose we consider scaled model (\\(range f=\\{-1,1\\}\\))\nat stage m\nwe want to opt the following\n\\[\n\\min_{(a,G)}\\sum_{i=1}^Nexp\\left(-y_i(f_{m-1}(x_i)+aG(x_i))\\right)\\\\\n=\\sum w_iexp(-y_iaG(x_i))\n\\]\nbasically using forward-stagewise method, if we fix \\(a\\)\n\\[\\begin{align}\n&exp(a)\\sum_{y_i\\neq G(x_i)}w_i+exp(-a)\\sum_{y_i=G(x_i)}w_i\\\\\n=&exp(a)\\sum_i^N w_i - exp(a)\\sum_{y_i=G(x_i)}w_i+\\dots\\\\\n=&(exp(-a)-exp(a))\\sum_{y_i=G(x_i)} w_i + exp(a)\\sum_i^Nw_i\\\\\n=&A\\sum_i^Nw_i[y_i\\neq G(x_i)]+\\dots\n\\end{align}\\]\nso actually, we are minimizing a weighted dataset using 0-1 loss\nwith this new solved \\(G\\), we can then solve for \\(a\\)\n\\[\\begin{align}\n&\\frac{d \\sum w_iexp(-aG(x_i))}{da}\\\\\n=&-\\sum w_iy_iG(x_i)exp(-ay_iG(x_i))\\\\\n=&-(exp(-a)+exp(a))\\sum_{y_i=G(x_i)} w_i + exp(a)\\sum_i^Nw_i=0\n\\end{align}\\]\nin short, AdaBoost.M1 is directly abtained from forward-stagewise method. With exp loss, we can get this neat sol.\nfurther, since \\(f_m=f_{m-1}+G_m\\), the weights \\(w_i\\) can be calculated iteratively.\n\n\n\n\\(f^\\star=arg \\min_fE_{Y|x}(e^{-Yf(x)})=\\frac{1}{2}log\\frac{Pr(Y=1|x)}{Pr(Y=-1|x)}\\), it est one half the log odds of \\(Pr(Y=1|x)\\), and \\(Pr(Y=1|x)=\\frac{1}{1+e^{-2f}}\\)\nlet \\(p(x)=Pr(Y=1|x)=\\frac{1}{1+e^{-2f}}\\) and \\(Y^\\prime =(Y+1)/2\\), we can see that cross-entropy and exp loss are actually est the same population.\n\nce: \\(-l(Y,f(x))=log(1+e^{-2Yf(x)})=Y^\\prime logp(x)+(1-Y^\\prime)log(1-p(x))\\), (f is softmaxed before output)\nexp: \\(e^{-Yf}\\)\nsame Pr, and f\n\n\n\n\n\n\nhere robustness means being disturbed less by outlier samples.\n\n\n\nsquared-error -&gt; \\(f(x)=\\mathbf{E}(Y|x)\\), more focus on obs with large absolute residuals during fitting process, far less robust, bad on long-tailed error distrb, gross outliers\nabsolute loss -&gt; median\nHuber loss. \\([y-f(x)]^2 \\text{ for abs residual } \\leq \\delta \\text{ and } 2\\delta|y-f(x)|-\\delta^2 \\text{ otherwise }\\)\n\n\n\n\nloss and robustness on regression prob\n\n\n\n\n\nwe consider two-class classification problem\nin regression problem, \\(y-f(x)\\) is considered as the margin\nin classif.., \\(yf(x)\\) plays the same role. where \\(y\\in\\{-1,1\\}\\)\n\n\n\nLoss functions for two-class classification.\n\n\n\n\n\nsquared-error, and exp loss are not robust, but give rise to simple boosting algorithms."
  },
  {
    "objectID": "posts/esl/ESL-01.html#boosting",
    "href": "posts/esl/ESL-01.html#boosting",
    "title": "The elements of statistical learning 01",
    "section": "",
    "text": "committee from a bunch of weak learners\\(G_m\\)(slightly better than rand)\n\\[\nG(x)=sign\\left(\\sum_{m=1}^Ma_mG_m(x)\\right)\n\\]\none generic method is forward-stagewise method where you compute one model \\(G_m\\) and its correspd weight \\(a_m\\) at a time (min \\(L(y_i, f_m(x_i)+\\beta G_m(x_i))\\)).\nif using MSE as the \\(L\\) loss, each time we are seeking for a model \\(\\beta G\\) that fit the residual.\n\n\niteratively fit \\(G_m\\) on a weighted dataset.\nmethod derived by using exp loss instead of the common mse ..\n\\[e^{-y_if(x_i)}\\]\nsuppose we consider scaled model (\\(range f=\\{-1,1\\}\\))\nat stage m\nwe want to opt the following\n\\[\n\\min_{(a,G)}\\sum_{i=1}^Nexp\\left(-y_i(f_{m-1}(x_i)+aG(x_i))\\right)\\\\\n=\\sum w_iexp(-y_iaG(x_i))\n\\]\nbasically using forward-stagewise method, if we fix \\(a\\)\n\\[\\begin{align}\n&exp(a)\\sum_{y_i\\neq G(x_i)}w_i+exp(-a)\\sum_{y_i=G(x_i)}w_i\\\\\n=&exp(a)\\sum_i^N w_i - exp(a)\\sum_{y_i=G(x_i)}w_i+\\dots\\\\\n=&(exp(-a)-exp(a))\\sum_{y_i=G(x_i)} w_i + exp(a)\\sum_i^Nw_i\\\\\n=&A\\sum_i^Nw_i[y_i\\neq G(x_i)]+\\dots\n\\end{align}\\]\nso actually, we are minimizing a weighted dataset using 0-1 loss\nwith this new solved \\(G\\), we can then solve for \\(a\\)\n\\[\\begin{align}\n&\\frac{d \\sum w_iexp(-aG(x_i))}{da}\\\\\n=&-\\sum w_iy_iG(x_i)exp(-ay_iG(x_i))\\\\\n=&-(exp(-a)+exp(a))\\sum_{y_i=G(x_i)} w_i + exp(a)\\sum_i^Nw_i=0\n\\end{align}\\]\nin short, AdaBoost.M1 is directly abtained from forward-stagewise method. With exp loss, we can get this neat sol.\nfurther, since \\(f_m=f_{m-1}+G_m\\), the weights \\(w_i\\) can be calculated iteratively.\n\n\n\n\\(f^\\star=arg \\min_fE_{Y|x}(e^{-Yf(x)})=\\frac{1}{2}log\\frac{Pr(Y=1|x)}{Pr(Y=-1|x)}\\), it est one half the log odds of \\(Pr(Y=1|x)\\), and \\(Pr(Y=1|x)=\\frac{1}{1+e^{-2f}}\\)\nlet \\(p(x)=Pr(Y=1|x)=\\frac{1}{1+e^{-2f}}\\) and \\(Y^\\prime =(Y+1)/2\\), we can see that cross-entropy and exp loss are actually est the same population.\n\nce: \\(-l(Y,f(x))=log(1+e^{-2Yf(x)})=Y^\\prime logp(x)+(1-Y^\\prime)log(1-p(x))\\), (f is softmaxed before output)\nexp: \\(e^{-Yf}\\)\nsame Pr, and f\n\n\n\n\n\n\nhere robustness means being disturbed less by outlier samples.\n\n\n\nsquared-error -&gt; \\(f(x)=\\mathbf{E}(Y|x)\\), more focus on obs with large absolute residuals during fitting process, far less robust, bad on long-tailed error distrb, gross outliers\nabsolute loss -&gt; median\nHuber loss. \\([y-f(x)]^2 \\text{ for abs residual } \\leq \\delta \\text{ and } 2\\delta|y-f(x)|-\\delta^2 \\text{ otherwise }\\)\n\n\n\n\nloss and robustness on regression prob\n\n\n\n\n\nwe consider two-class classification problem\nin regression problem, \\(y-f(x)\\) is considered as the margin\nin classif.., \\(yf(x)\\) plays the same role. where \\(y\\in\\{-1,1\\}\\)\n\n\n\nLoss functions for two-class classification.\n\n\n\n\n\nsquared-error, and exp loss are not robust, but give rise to simple boosting algorithms."
  },
  {
    "objectID": "posts/esl/ESL-01.html#specific-boosting-example",
    "href": "posts/esl/ESL-01.html#specific-boosting-example",
    "title": "The elements of statistical learning 01",
    "section": "specific boosting example",
    "text": "specific boosting example\n\nboosting tree\nregion \\(R_j,\\, j=1,\\dots,J\\)\n\\(x\\in R_j\\mathbb{R}ightarrow f(x)=y_j\\)"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html",
    "href": "posts/paper-reading/multi-view-clustering.html",
    "title": "some papers about multi-view-clustering",
    "section": "",
    "text": "very brief summaries of some papers I read"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#binary-multi-view-clustering",
    "href": "posts/paper-reading/multi-view-clustering.html#binary-multi-view-clustering",
    "title": "some papers about multi-view-clustering",
    "section": "Binary Multi-View Clustering",
    "text": "Binary Multi-View Clustering\nlarge scale multi-view image clustering\njointly learn collaborative discrete representation and binary cluster structures\nhas an algorithm with proved convergence analysis"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#contrastive-clustering",
    "href": "posts/paper-reading/multi-view-clustering.html#contrastive-clustering",
    "title": "some papers about multi-view-clustering",
    "section": "Contrastive Clustering",
    "text": "Contrastive Clustering\nunified instance- and cluster-level contrastive learning\nrow vectors and column vectors as instance representation and cluster representation\nQ: how to construct negative instance, how to design the training target"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#deep-clustering-on-the-link-between-discriminative-models-and-k-means",
    "href": "posts/paper-reading/multi-view-clustering.html#deep-clustering-on-the-link-between-discriminative-models-and-k-means",
    "title": "some papers about multi-view-clustering",
    "section": "Deep Clustering: On the Link between Discriminative Models and K-Means",
    "text": "Deep Clustering: On the Link between Discriminative Models and K-Means\ndiscover the equivilance between discriminative models using L2 regularized MI loss and soft regularized K-means loss, under some conditions"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#multiview-clustering-a-scalable-and-parameter-free-bipartite-graph-fusion-method",
    "href": "posts/paper-reading/multi-view-clustering.html#multiview-clustering-a-scalable-and-parameter-free-bipartite-graph-fusion-method",
    "title": "some papers about multi-view-clustering",
    "section": "Multiview Clustering: A Scalable and Parameter-Free Bipartite Graph Fusion Method ",
    "text": "Multiview Clustering: A Scalable and Parameter-Free Bipartite Graph Fusion Method \nparameter-free, graph based multi-view clustering (graph fusion frameswork ?)"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#dual-contrastive-prediction-for-incomplete-multi-view-representation-learning",
    "href": "posts/paper-reading/multi-view-clustering.html#dual-contrastive-prediction-for-incomplete-multi-view-representation-learning",
    "title": "some papers about multi-view-clustering",
    "section": "Dual Contrastive Prediction for Incomplete Multi-view Representation Learning ",
    "text": "Dual Contrastive Prediction for Incomplete Multi-view Representation Learning \nin-complete MvRL\nunify consistency learning and missing data recovery: proved using information theory\nframework based on contrastive learning loss"
  },
  {
    "objectID": "posts/paper-reading/multi-view-clustering.html#robust-multi-view-clustering-with-incomplete-information",
    "href": "posts/paper-reading/multi-view-clustering.html#robust-multi-view-clustering-with-incomplete-information",
    "title": "some papers about multi-view-clustering",
    "section": "Robust Multi-view Clustering with Incomplete Information",
    "text": "Robust Multi-view Clustering with Incomplete Information\nunified framework to solve PVP and PSP\ncontrastive loss to eliminate the false negative samples"
  },
  {
    "objectID": "posts/paper-reading/moco.html",
    "href": "posts/paper-reading/moco.html",
    "title": "MoCo",
    "section": "",
    "text": "动量对比学习(Momentum Contrast, MoCo)用于图象表征的无监督学习。主要的观点是将对比学习看作是一种字典查询，即给定一个图片的编码作为请求，在字典中找到与之对应的图片编码。并依此提出了在视觉领域中，使用这种方法需要面临的两个关键点：一是字典应尽可能的大；二是在训练过程中用于编码字典的编码器应尽可能地保持一致，也就是要保证所有的图片都大致映射到了同一个表征空间中。为解决第一个问题，作者提出了使用队列动态维护字典；针对第二个问题，使用动量更新的方法去修改编码器的参数。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#background",
    "href": "posts/paper-reading/moco.html#background",
    "title": "MoCo",
    "section": "Background",
    "text": "Background\n无监督学习的方法在自然语言处理(NLP)领域取得了很大的成功，这得益于在 NLP 中，模型面对的输入信号是离散的，同时易于分割成小的单元来建造字典或者对应的表征。而在视觉领域，输入的信号是连续的、高维度的、非结构化的，想要得到同样效果的稀疏的表征是很困难的。\n无监督学习在大型无标记数据集上的使用是非常值得关注的，使用无监督学习来与训练得到的表征也能用于下游任务的学习。但他的效果却并不如目前的监督式学习效果好。若能很好的解决这一表征学习的问题，则能大大缩小监督与无监督学习之间的差距。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#retated-work",
    "href": "posts/paper-reading/moco.html#retated-work",
    "title": "MoCo",
    "section": "Retated Work",
    "text": "Retated Work\n为了解决以上提出的问题，很多研究提出了不同的基于对比学习的方法。\n\nloss function\n最早期的方法中，我们的目标是寻找一种编码器负责降维以及特征的学习，以成对的数据作为输入，以他们的距离来表达相似度。为此，损失函数分为两部分，前者用来缩小相似数据的距离，后者用来扩大不相似数据的距离。\n之后转化成使用互信息建模，提出 InfoNCE 损失函数。采样正负样本进行训练。最终普遍使用的是非参数化的softmax函数。\n\\[P(i|v)=\\frac{\\exp(v_i^Tv/\\tau)}{\\sum_{j=1}^{n}{\\exp(v_j^Tv/\\tau)}}\\]\n\n\ncontrastive loss mechanisms\n\nend-to-end\n端到端的方法中，当前的batch被作为字典进行训练，query和key分别采用不同的编码器，并分别进行梯度下降。由于算力的限制，更大的字典难以进行梯度的计算，同时他也受限于batch的大小。他的一致性保持得很好，因为一个batch字典的编码器总是同一个，但缺点是字典数量难以保证。\n\n\nmemory bank\n另一种机制是提前将所有样本的编码计算出来，每次query时，会在所有样本中再进行采样作为字典。同时，我们不再对key的编码器进行梯度下降，而是直接使用query的参数。注意，这里的更新是不及时的，每次只有当前被采样的样本编码被更新了。这样字典大小的问题解决了，但一致性的问题却变得棘手，因为每次采样的编码可能是由不同的编码器(参数不同)得到。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#novelty",
    "href": "posts/paper-reading/moco.html#novelty",
    "title": "MoCo",
    "section": "novelty",
    "text": "novelty\nMoCo 提出使用队列来动态维护字典，成功做到了字典大小完全不依赖batch的大小。新的batch被加入到队列中，最旧的batch会被移除。这样，队列中的keys使用的编码器是连续、平滑的更新的。\n第二点是key编码器参数的更新上，并不是直接复制query的参数，而是动量更新，更加的平滑，保证了一致性。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#dict-look-up",
    "href": "posts/paper-reading/moco.html#dict-look-up",
    "title": "MoCo",
    "section": "dict look-up",
    "text": "dict look-up\n与上文提到的 memory-bank 方法类似，根据一个样本，通过随机变换得到新样本作为正例，之后取 K 个负例求出 InfoNCE loss 进行优化。不同的是负例的选择方式和编码器的更新方式。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#momentum-contrast",
    "href": "posts/paper-reading/moco.html#momentum-contrast",
    "title": "MoCo",
    "section": "Momentum Contrast",
    "text": "Momentum Contrast\n\nqueue\n每次取得一个新的batch数据进行随机增强作为请求 q，再做另一种随机增强作为每个单独请求的正例 k。将队列中的全部元素作为每个请求的负例，求得损失，利用梯度下降更新参数。随后将 k 加入到队列中，同时去掉旧的batch。 由于队列的规模会很大，队列中的编码加入队列后并不会再更新，但这并不会妨碍一致性的保证，因为它总会把最不一致的编码去除掉。\n\n\nMomentum update\n在更新参数时，只对query的编码器参数进行梯度下降，而对key编码器进行如下更新: \\[\\theta_k \\leftarrow m\\theta_k+(1-m)\\theta_q\\]\n而在实验中，稍大的 m 得到的结果会更好，这也印证了一致性的重要。\n\n\nPretext Task\n前置任务与 memory-bank 类似。这里作者采用了 ResNet 作为编码器，而作者通过实验发现 BN 对编码的学习起到了消极的作用，而这可能是由于 BN 融合了当前batch的信息，在一定程度上会使模型”走捷径”。\n对 BN 的问题，作者提出了 shuffling BN 的方法，也就是在 BN 前先将 sample 进行打乱，求得编码后再复原。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#training",
    "href": "posts/paper-reading/moco.html#training",
    "title": "MoCo",
    "section": "training",
    "text": "training\n数据集采用的是\n\nImageNet: 包含约 1 百万张图片，1000 个类别。图片的类别分布均匀\nInstagram: 由 Instagram 中得到的约 10 亿张图片。具有长尾分布。\n\n这里作者是将特征层冻结，微调线性分类层来验证模型的效果。与众多无监督模型进行比对。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#findings",
    "href": "posts/paper-reading/moco.html#findings",
    "title": "MoCo",
    "section": "findings",
    "text": "findings\n\n在微调MoCo时，一些超参数与监督式学习模型相差很大，这表明他们的特征分布有较大的差异\n通过与 end-to-end 和 memory-bank 两种方法的对比可以发现，当字典规模较小时，end-to-end 模型和 MoCo 不相上下，memory-bank 则稍逊风骚；但增大字典规模后，end-to-end 模型则受限于算力，无法计算，其他两个模型都可以持续增加，但 MoCo 则明显胜出许多。说明 MoCo 很大的提升了无监督学习的效果。\n若完全复制query编码器参数，则无法收敛\nMoCo 可以很好的作为pre-trained模型进行下游任务的学习。"
  },
  {
    "objectID": "posts/paper-reading/moco.html#conclusion",
    "href": "posts/paper-reading/moco.html#conclusion",
    "title": "MoCo",
    "section": "conclusion",
    "text": "conclusion\nMoCo 提供了一种对比学习的框架，在能够使字典尽可能大的同时，还可以保证表征空间的一致性。这是一种非常简洁而有效的方法。"
  },
  {
    "objectID": "posts/programming/vim_tech.html",
    "href": "posts/programming/vim_tech.html",
    "title": "vim techs",
    "section": "",
    "text": "add key mapping yourself\nsave below as xxx.vim in /path/to/nerdtree/nerdtree_plugin/xxx.vim\nyy for abs path of current node, yr for rel path\n```{vimscript}\ncall NERDTreeAddKeyMap({\n        \\ 'key': 'yy',\n        \\ 'callback': 'NERDTreeYankFullPath',\n        \\ 'quickhelpText': 'put full path of current node into the default register' })\n\nfunction! NERDTreeYankFullPath()\n    let n = g:NERDTreeFileNode.GetSelected()\n    if n != {}\n        call setreg('\"', n.path.str())\n    endif\n    call nerdtree#echo(\"Node full path yanked!\")\nendfunction\n\ncall NERDTreeAddKeyMap({\n        \\ 'key': 'yr',\n        \\ 'callback': 'NERDTreeYankRelativePath',\n        \\ 'quickhelpText': 'put relative path of current node into the default register' })\n\n\nfunction! NERDTreeYankRelativePath()\n    let n = g:NERDTreeFileNode.GetSelected()\n    if n != {}\n        call setreg('\"', fnamemodify(n.path.str(), ':.'))\n    endif\n    call nerdtree#echo(\"Node relative path yanked!\")\nendfunction\n```"
  },
  {
    "objectID": "posts/programming/vim_tech.html#yank-abs-path-or-relative-path-in-nerdtree",
    "href": "posts/programming/vim_tech.html#yank-abs-path-or-relative-path-in-nerdtree",
    "title": "vim techs",
    "section": "",
    "text": "add key mapping yourself\nsave below as xxx.vim in /path/to/nerdtree/nerdtree_plugin/xxx.vim\nyy for abs path of current node, yr for rel path\n```{vimscript}\ncall NERDTreeAddKeyMap({\n        \\ 'key': 'yy',\n        \\ 'callback': 'NERDTreeYankFullPath',\n        \\ 'quickhelpText': 'put full path of current node into the default register' })\n\nfunction! NERDTreeYankFullPath()\n    let n = g:NERDTreeFileNode.GetSelected()\n    if n != {}\n        call setreg('\"', n.path.str())\n    endif\n    call nerdtree#echo(\"Node full path yanked!\")\nendfunction\n\ncall NERDTreeAddKeyMap({\n        \\ 'key': 'yr',\n        \\ 'callback': 'NERDTreeYankRelativePath',\n        \\ 'quickhelpText': 'put relative path of current node into the default register' })\n\n\nfunction! NERDTreeYankRelativePath()\n    let n = g:NERDTreeFileNode.GetSelected()\n    if n != {}\n        call setreg('\"', fnamemodify(n.path.str(), ':.'))\n    endif\n    call nerdtree#echo(\"Node relative path yanked!\")\nendfunction\n```"
  },
  {
    "objectID": "posts/programming/vim_tech.html#add-sth.-surround",
    "href": "posts/programming/vim_tech.html#add-sth.-surround",
    "title": "vim techs",
    "section": "add sth. surround",
    "text": "add sth. surround\nys takes a motion or text object, and then the char you want to put surround with\nlike ysiw\" surr current word with \""
  },
  {
    "objectID": "posts/notes-about-technical-writing.html",
    "href": "posts/notes-about-technical-writing.html",
    "title": "Notes about Technical Writing",
    "section": "",
    "text": "extra spaces between words and extra blank lines between passages will be ignored.\n\nspaces in the front will be ignored.\nnewline is regarded as an extra space, adding % at the end will remove it.\nnote: space before macros will not be ignored, e.g., \\TeX ing. But spaces at the rear will be ignored. Adding brankets {} will resolve it, e.g., {\\TeX} ing or \\Tex{} ing.\n\n\\qquad: as wide as about two M s\ndouble hyphen: -- denotes number range, en dash; triple hyphen: --- denotes punctuation dash, em dash. en and em denotes the width\nfloat environment: e.g., figure, table. accept an optional arg (h: here; t: top; H: here and not float, extended from package float)\n\\eqref is specified for math equations from package amsmath\navoid setting font or controlling indents, etc., within the document environment. try to replace them with meaningful commands or environments.\n\n\\newenvironment{myenv}\n\\newcommand\n\nellipsis: \\ldots or \\dots. instead of \\cdots or ...(three dots).\n\nH\\dots. (OK)\nH \\ldots H (not good), H $\\ldots$ H (recommended, math env)\n\nescape chars in the main body.\n\n\\_ for _; \\textbackslash for \\\n\nnon-breakable space.\n\nQuestion~1\nDonald~E. Knuth within names\nMr.~Knuth\nfunction~$f(x)$\n1,~2, and~3\n\nperiod after capital is regarded as a abbreviation. use \\ or \\@ to resolve it. E.g., Roman number XII\\@. Yes.\nBibTeX\n\n\\citep (index) and \\citet (author) are recommended. remember to use package natbib and use plainnat bibliography style\n\nforce line break\n\n\\\\ accepts an optional argument for vertical space. e.g., \\\\[2cm]. Often used for in equation environment\n\nspecial chars used in main body\n\n§: \\S\n: \\dag\n: \\ddag\n¶: \\P\n©: \\copyright\n£: \\pounds\n\\(\\bullet\\): \\textbullet (\\bullet in math env)\ngo check the book The Comprehensive LATEX Symbol List, 2009 by Scott Pakin for more"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#font-family",
    "href": "posts/notes-about-technical-writing.html#font-family",
    "title": "Notes about Technical Writing",
    "section": "font family",
    "text": "font family\n\nroman family: \\textrm{font family} font family\nsans-serif family: \\textsf{font family} font family\ntypewritter family: \\texttt{font family} font family\n\ndeclaration, {\\rmfamily font family} font family"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#font-shape",
    "href": "posts/notes-about-technical-writing.html#font-shape",
    "title": "Notes about Technical Writing",
    "section": "font shape",
    "text": "font shape\n\nupright shape: \\textup{Font Shape} Font Shape\nitalic shape: \\textit{Font Shape} Font Shape\nslanted shape: \\textsl{Font Shape} Font Shape\nsmall captical shape: \\textsc{Font Shape} Font Shape\n\ndeclaration: {\\itshape Font Shape} Font Shape"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#font-series",
    "href": "posts/notes-about-technical-writing.html#font-series",
    "title": "Notes about Technical Writing",
    "section": "font series",
    "text": "font series\n\nmedium series: \\textmd{font series} font series (default in main body)\nbold series: \\textbf{font series} font series\n\ndeclaration: {\\mdseries font series} font series"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#font-typeface",
    "href": "posts/notes-about-technical-writing.html#font-typeface",
    "title": "Notes about Technical Writing",
    "section": "font typeface",
    "text": "font typeface\n\nThe default font family of \\(\\LaTeX\\) is Computer Modern\nSerif Times Roman (i.e., Times New Roman) is recommended for papers, magazines and books. Use package txfonts\nConcrete is recommended for presentation. package combination ccfonts, eulervm is great. (also arec ,cmbright)\n\nwe can specify three font family individually\n\\usepackage{fontspec}\n\\setmainfont{Times New Roman}\n\\setsansfont{Verdana}\n\\setmonofont{Courier New}"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#emphasis",
    "href": "posts/notes-about-technical-writing.html#emphasis",
    "title": "Notes about Technical Writing",
    "section": "emphasis",
    "text": "emphasis\nmake upright or make italic upright\n\nthis is \\emph{emphasis}: this is emphasis\n\\textit{this is \\emph{emphasis}} this is emphasis**\n\nunderline\n\\underline{Emphasized} text and \\underline{another}: Emphasized text and another\nuse package \\usepackage[normalem]{ulem}\n\\uline{Emphasized} text and \\uline{another}: Emphasized text and another"
  },
  {
    "objectID": "posts/notes-about-technical-writing.html#font-size",
    "href": "posts/notes-about-technical-writing.html#font-size",
    "title": "Notes about Technical Writing",
    "section": "font size",
    "text": "font size"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-03.html",
    "href": "posts/parallel-algorithm/PA-03.html",
    "title": "parallel algorithm course 03",
    "section": "",
    "text": "recursion\nscan\nmap, reduce, scan"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-03.html#compact-alg",
    "href": "posts/parallel-algorithm/PA-03.html#compact-alg",
    "title": "parallel algorithm course 03",
    "section": "compact alg",
    "text": "compact alg\npick up using an indication arr\nA = 0 1 2 3 4 5 6 F = 0 1 1 0 0 1 0\noutput = 1 2 5\nkey to do parallel, acknowledge the target position in advance\nscan F\nidx = 0 1 2 2 2 3 3"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-03.html#fragment-sum",
    "href": "posts/parallel-algorithm/PA-03.html#fragment-sum",
    "title": "parallel algorithm course 03",
    "section": "fragment sum",
    "text": "fragment sum\n\napplication\n\nF zero flag put in the front, one flag in the back\ntwo stage compact, \\(F^{-1}\\) first, then use \\(F\\)\n\nscatter\n\n\n\nwhat is scatter\n\n\nmake it into a large sparse matrix and then reduce sum\n\nbinary base sort\nRadix sort.\nfor from lowbit to highbit\n\nscan\n\\(T_1(n,b)=O(bn)\\)\n\\(T_\\infty(n,b)=(blogn)\\)\nif from highbit to lowbit, need fragment scan\nbit-wise thinking."
  },
  {
    "objectID": "posts/parallel-algorithm/PA-08.html",
    "href": "posts/parallel-algorithm/PA-08.html",
    "title": "parallel algorithm course 08",
    "section": "",
    "text": "openACC\nGPU not sharable\nopenacc.org\nopenacc best programming\nthree levels\ndata"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-08.html#optimize",
    "href": "posts/parallel-algorithm/PA-08.html#optimize",
    "title": "parallel algorithm course 08",
    "section": "optimize",
    "text": "optimize\nUnified virtual memory, auto, slow\nremove the “managed” suboption to the -ta compiler\ndata clauses\nallocate with copy\n\ncopyin {list}: cpu \\(\\to\\) gpu\ncopyout {list}: gpu \\(\\to\\) cpu\ncopy {list}\n\nallocate without copy\n\ncreate {list}\ndelete {list}\n\nonly copy\n\npresent {list}: only copy if present when copyin\n\npragma\n#pragam acc data copyin (a[0:nelem]) copyout(b[s/4:3*s/4])\nrun functions in each devices, and do copyin, copyout in the functions\nslow\nwe can copyin and copyout together\n\ndata\n\n#pragma acc data\n{\n    #pragma acc parallel loop\n    ...\n    #pragma acc parallel loop\n    ...\n}\ncopyin and copyout in each loops are done in one clause\n\nenter data: copyin, create\nexit data: copyout, delete, finalize(destroy a variable not regarding its reference)\nclass M{\n    M() {\n        v = new double[N];\n        #pragma acc enter data create(v)\n    }\n    ~M() {\n        #pragma acc exit data delete(v)\n        {\n            free(v);\n        }\n    }\n}\n\nrunning with explicit data management\ndata racing update between cpu and gpu\ndo_somthing_on_device();\n\n#pragma acc update host(a)\n\ndo_something_on_host();\n\n#pragma acc update device(a)\n\nreduce IO between cpu and GPU"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-08.html#optimize-loops",
    "href": "posts/parallel-algorithm/PA-08.html#optimize-loops",
    "title": "parallel algorithm course 08",
    "section": "optimize loops",
    "text": "optimize loops\noptimize matvec loops\ndefault iteration is 128 for GPU\nthree level\nGang, workers, vectors\none SMP \\(\\to\\) 64 cores, 16 warps(1 warp = 32 threads), at most 2048 threads\n\nset vector size as 32 k\n\nworker = warp \n#pragma acc parallel vector_length(32)\n#pragma acc loop gang worker\nfor (int i = 0; i &lt; n; i++)\n    #pragma acc loop vector // vector loop\n    for (int j = 0; j &lt; i; j++)\nvector loop: has to specify vector_length or num_workers\ncollapse clause\n#pragma acc parallel loop collapse(2)\nfor (i)\n    for (j)\nequiv\n#pragma acc parallel loop\nfor (ij)\n\nthe tile clause\noperate on smaller blocks of the operation to exploit data locality\n\nstride-1 memory access\ncontinus access\na[0][i][j]"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html",
    "href": "posts/parallel-algorithm/pa-06.html",
    "title": "parallel algorithm course 06",
    "section": "",
    "text": "reiview\n\\(T_1(n)=O(n)\\)\n\\(T_\\infty(n)=O(log^k(n))\\)\nmodel: shared memory model"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html#core-alg",
    "href": "posts/parallel-algorithm/pa-06.html#core-alg",
    "title": "parallel algorithm course 06",
    "section": "core alg",
    "text": "core alg\n\nmap \\(\\text{n}\\to \\text{n}\\)\nreduce \\(\\text{n} \\to 1\\)\nscan: compact (based on scan)\nlist ranking\nsort alg\nradix sort, sample sort"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html#goal",
    "href": "posts/parallel-algorithm/pa-06.html#goal",
    "title": "parallel algorithm course 06",
    "section": "goal",
    "text": "goal\n\ncomplexity optimal\ndependency –\nsymetric – (symetry: hard to find independency) using rand (find independent set) or odd-even"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html#thinking",
    "href": "posts/parallel-algorithm/pa-06.html#thinking",
    "title": "parallel algorithm course 06",
    "section": "thinking",
    "text": "thinking\n\ncase to general\nforward-backward\nbit-wise thinking\nmatrix thinking"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html#pattern",
    "href": "posts/parallel-algorithm/pa-06.html#pattern",
    "title": "parallel algorithm course 06",
    "section": "pattern",
    "text": "pattern\n\ndivide and conquer\nindependent set\nrandom\njump"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-06.html#openmp",
    "href": "posts/parallel-algorithm/pa-06.html#openmp",
    "title": "parallel algorithm course 06",
    "section": "OpenMP",
    "text": "OpenMP\n\npipeline: serial \\(\\to\\) independent \\(\\to\\) group \\(\\to\\) parallel\ndata racing, using syncronization\nPseudo random number generator"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-02.html",
    "href": "posts/parallel-algorithm/PA-02.html",
    "title": "parallel algorithm course 02",
    "section": "",
    "text": "problem \\(T_1\\)\n-&gt; reduce dependency -&gt;\ntasks \\(T_\\infin\\)\nwork sharing\nblocks\nsynchronization (better to avoid)\nfalse sharing"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-02.html#review",
    "href": "posts/parallel-algorithm/PA-02.html#review",
    "title": "parallel algorithm course 02",
    "section": "",
    "text": "problem \\(T_1\\)\n-&gt; reduce dependency -&gt;\ntasks \\(T_\\infin\\)\nwork sharing\nblocks\nsynchronization (better to avoid)\nfalse sharing"
  },
  {
    "objectID": "posts/parallel-algorithm/PA-02.html#sync",
    "href": "posts/parallel-algorithm/PA-02.html#sync",
    "title": "parallel algorithm course 02",
    "section": "sync",
    "text": "sync\nSingle program multiple data\nseq\nfor(i=0;i&lt;N;i++) a[i] = a[i] + b[i];\nomp par\n#pragma omp parallel\n{\n    id = omp_get_thread_num();\n    Nthrds\n    i_start = id * N / Nthrds\n    i_end = (id+1) * N / Nthrds\n    if (id==Nthrds - 1) iend=N\n    for (i=istart;i&lt;iend;i++) ...    \n}\nshorter (but slower)\n#pragma omp parallel {\n    #pragma omp for\n        for () ...\n}\n\n// or equiv\n\n#pragma omp parallel for\n...\n\nloop worksharing constructs\nschedule clause\n\nstatic: least work for scheduling (done at compiling)\ndynamic (complex scheduling at run-time)\n\n\nreduction\nop should be associative\n+,*,-,min,max\n#pragma omp parallel for reduction (+: sum)\n    for (i=0; i &lt; num_steps; i++)\n        x = ...\n        sum = sum + x\nslower than SPMD critical\n\nomp for loop has barrier by default\nhas implicit barrier\nuse nowait to cancel it\n\nmaster construct\n#pragma omp master\nonly master thread will execute\nno barrier for other threads\n\n#pragma omp single\nonly one thread will execute, has barrier\nuse nowait to cancel barrier\n\nsections\n#pragma omp sections\n{\n    #pragma omp section\n        thread A\n    #pragma omp section\n        thread B\n}\nA, B will execute in parallel\nhas barrier at the end of sections\n\nlock routines\nomp_init_lock();\nomp_set_lock(), omp_unset_lock()\nomp_destroy_lock()\ne.g. array\nif use critical on a[i], then the whole array a will be lock\n#bins \\(\\gg\\) #threads\nlow prob of false sharing, conficts are rare, use locks\n\nOMP refernce card\n\nomp_set_dynamic()\n\nenv vars\nOMP_NUM_THREADS\n\nheap: shared\nstack: private\nint tmp=0; // in heap\n#pragma omp parallel for private(tmp)\n    for (int i; i &lt; N; i++) {\n        tmp += j; // not initialized, local copy ( in stack )\n    }\nprint(tmp); // 0 here\nint tmp=999; // in heap\n#pragma omp parallel for firstprivate(tmp)\n    for ()\n        tmp += j; // has initialized with 1, local copy ( in stack ), still private\n\nprintf(tmp) // 999\nnot use often: lastprivate\nint tmp=0; // in heap\n#pragma omp parallel for lastprivate(j)\n    for ()\n        tmp = j; // copy the last j to tmp\n    \nprint(tmp); // print the last j"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-05.html",
    "href": "posts/parallel-algorithm/pa-05.html",
    "title": "parallel algorithm course 05",
    "section": "",
    "text": "omp task\narray pool\nuse array to simulate linked list\n\n\nfind prev using next\n\n\n\nfind index\nprev\njump\nrepeat:\npar-for i from 0 to n-1:\n    if NULL: continue\n    if prev[i] != empty:\n        rank[i] += rank[prev[i]] # initial all 1 except head is 0\n        prev[i] = prev[prev[i]] # use 2 copies to avoid data racing\n\\(T_1(n)=O(n\\cdot log(n))\\)\n\\(T_\\infty(n)=O(log(n))\\)\nWyllie’s Alg: jump\n\n\n\nsimilar: binary lifting"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-05.html#linked-list",
    "href": "posts/parallel-algorithm/pa-05.html#linked-list",
    "title": "parallel algorithm course 05",
    "section": "",
    "text": "omp task\narray pool\nuse array to simulate linked list\n\n\nfind prev using next\n\n\n\nfind index\nprev\njump\nrepeat:\npar-for i from 0 to n-1:\n    if NULL: continue\n    if prev[i] != empty:\n        rank[i] += rank[prev[i]] # initial all 1 except head is 0\n        prev[i] = prev[prev[i]] # use 2 copies to avoid data racing\n\\(T_1(n)=O(n\\cdot log(n))\\)\n\\(T_\\infty(n)=O(log(n))\\)\nWyllie’s Alg: jump\n\n\n\nsimilar: binary lifting"
  },
  {
    "objectID": "posts/parallel-algorithm/pa-05.html#improve-wyllies-alg",
    "href": "posts/parallel-algorithm/pa-05.html#improve-wyllies-alg",
    "title": "parallel algorithm course 05",
    "section": "improve Wyllie’s Alg",
    "text": "improve Wyllie’s Alg\n\\(O(n\\cdot log(n))\\rightarrow O(n)\\)\n\nstep 1: shrink \\(n\\rightarrow m\\)\nstep 2: call Wyllie’s Alg \\(O(m\\cdot log(m))\\)\nstep 3: restore \\(m\\rightarrow n\\)\n\ntarget \\(m\\rightarrow \\frac{n}{log(n)}\\)\nindependent set \\(\\forall i \\in I,N(i) \\notin I\\)\nsymetry break\n\nrandom flip coin, keep or remove\nresolve confict\n\n# producing independent set\n\npar-for i=1..n\n    F[i] = RND(0 or 1)\npar-for i=1..n\n    if F[i]=F[N[i]]=1: # data racing. need 2 copies\n        F[i] = 0\n\\(T_1(n)=O(n)\\)\n\\(T_\\infty(n)=O(1)\\)\n\\(\\mathbb{E}|I|=\\frac{n}{4}\\)\n\\([n]/I\\rightarrow \\frac{3}{4}n\\) repeat \\(loglog(n)\\) times \\(\\frac{n}{log(n)}\\)\n\n\ninitialized with 1 except head\nrepeatedly remove an independent set \\(S\\) til #rest=\\(\\frac{n}{logn}\\) (change next[prev[i]] to next[i], add counter[i] to counter[next[i]] forall \\(i\\in S\\))\ncall Wyllie’s Alg\nreverse\n\n\nquick sort: choose 1 pivot, sample 1\nv.s.\nsample sort: randomly choose \\(p-1\\) pivots, sample \\(k\\cdot p+1\\)\ncompact operator"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "",
    "text": "record video link on bilibili 👉 MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#main-question",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#main-question",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "main question",
    "text": "main question\nhow does “deep layers” work?\nDeep learning = hierarchical feature learning"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#observation",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#observation",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "observation",
    "text": "observation\n\nadding more layers and train holistically will improve the accuracy, though the previous layers are already fully converged.\nYou can’t expect what it learns from what you build"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#focused-object",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#focused-object",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "focused object",
    "text": "focused object\nwe only consider densenet with quadratic activation function\n\n\n\ndensenet"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#proof-target",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#proof-target",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "proof target",
    "text": "proof target\ndensenet with wider layers will learn a target densenet effeciently in arbitrary accuracy\n\n\n\n\n\n\nNote\n\n\n\n\n“wider” means overparameterize\n“efficient” means converging with arbitrary accuracy \\(\\epsilon\\) using \\(\\text{poly}(d,\\frac{1}{\\epsilon})\\) samples, \\(d\\) dimensions"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#assumptions",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#assumptions",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "assumptions",
    "text": "assumptions\n\nweight matrices in the target net are well-conditioned: not degenerated. the output will be a \\(2^L\\) degree poly\ninformation gap: let \\(a_i\\) be the coefficient in the linear combination of output, \\(a_i &gt;&gt; a_{i+1} &gt;&gt; 1/d^{0.01}\\). note: \\(G(x)=\\sum_i^La_iL_i\\), where \\(L_i\\) is the sum of the output nodes of layer \\(i\\)\n\\(L\\approx O(\\log\\log d)\\)\n\n\n\n\n\n\n\nNote\n\n\n\nshallow model will not learn efficiently, usually \\(d^{2^L}\\) samples, while deep model uses \\(2^{2^L}\\) samples which is \\(\\text{poly}(d)\\)"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#intuition-proof",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#intuition-proof",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "intuition proof",
    "text": "intuition proof\n\nStep 1: about overparameterization\nIf we wish to learn \\(G(x)=x_1^2+x_2^2+\\alpha(x_1^4+x_2^4)\\), \\(\\alpha=0.1\\)\nWe hope the first layer to learn \\(x_1^2\\), \\(x_2^2\\), second layer to learn \\(\\alpha(x_1^4+x_2^4)\\)\nbut first layer may give an output which we cannot reconstruct \\(x_1^4+x_2^4\\) from\nsolution: over-parametrization and Gaussian random init\n\n\n\n\n\n\nNoteconclusion\n\n\n\nrich representation for the next layer (not necessary useful for current layer)\n\n\n\n\nStep 2\nIf we wish to learn \\(G(x)=x_1^2+x_2^2+\\alpha((x_1^2+x_3)^2+(x_2^2+x_4)^2)\\), \\(\\alpha=0.1\\)\nChances are that the first layer learns \\((x_1+\\alpha x_3)^2+(x_2+\\alpha x_4)^2\\) from which the next layer cannot reconstruct the remaining terms\n\n\n\n\n\n\nNoteclaim\n\n\n\nlayer-wise training overfits to higher-level signals, not noise\n\n\nsolution: training both layers together, second layer will fix the first layer\n\n\nStep 3\nfirst layer: \\(\\alpha\\) close (to the ground-truth poly)\n\\(\\xrightarrow{learn}\\) second layer (learns the residual): \\(\\alpha^2\\) close\n\\(\\xrightarrow{correction}\\) first layer (correction): \\(\\alpha^2\\) close\n\\(\\xrightarrow{re-learn}\\) second layer: \\(\\alpha^4\\) close\n…\nmore layers means more corrections to the previous layers\n\n\n\n\n\n\nNoteclaim\n\n\n\nlayers are learned simoutaneously\n\n\nimportant: backward feature correction"
  },
  {
    "objectID": "posts/research/MSR-AI-Seminar-Feb-8.html#feature-visualization",
    "href": "posts/research/MSR-AI-Seminar-Feb-8.html#feature-visualization",
    "title": "MSR AI Seminar: Why Does Deep Learning Perform Deep Learning?",
    "section": "feature visualization:",
    "text": "feature visualization:\n\n\n\nBy Google AI, 2017\n\n\n\nfind the picture that activates a specific neuron the most by Gradient Descent\nweakness: relies on strong regularization to make it more like a image, otherwise a meaningless noise picture\n\n\n\n\n\n\nTiprelated\n\n\n\nadversarial perturbation"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-05.html",
    "href": "posts/understanding-machine-learning/UML-05.html",
    "title": "Understanding Machine Learning 05",
    "section": "",
    "text": "here we go to one of the famous theories, the VC dimension\nbefore going a little deeper, we will have a look at the motivation\n\n\nfirst, finite is not a sufficient and necessary condition of PAC learnability. exercise 3.3 is a simple example. Moreover, in the last post (No-Free-Lunch theorem), we have seen H that contains all possible functions is not PAC learnable. When we rethink the proof, we may notice that the construction of set \\(C\\) is the key point. Since we are considering all possible functions, the error of different f’s can cancel, resulting in a large error.\nborrow the idea, if we can find a subset \\(C\\) of domain \\(\\mathcal{X}\\), and if H contains all the functions when taking \\(C\\) as the domain, then it will cause a considerable risk using the same proof\nfurther, if such kind of \\(C\\) is infinitely large, then \\(H\\) is not learnable\nthe thoughts above give us the basic idea of how the VC dimension comes\n\n\n\n\nDef. restriction of H to C\nhere, \\(\\mathcal{C}=\\{c_1,c_2,\\dots,c_m\\}\\subseteq\\mathcal{X}\\)\nand \\(\\mathcal{H}_C=\\{h(c_1),\\dots,h(c_m)\\}\\)\n\nDef. Shattering\nH shatters C \\(\\iff\\) \\(|H_C|=2^{|C|}\\)\n\nDef. VC-dimension\nthe VC-dimension of H \\(\\coloneq\\max_C\\{|H_C|:\\text{H shatters C}\\}\\)\n\na simple method to show VCdim=d we need to show that\n\n\\(\\exists C\\) of size d that is shattered by H\nevery C of size d+1 is not shattered by H\n\n\nsince \\(2^{|VCdim(H)|}\\le |H|\\), we have a loose upper bound of VC dim which is \\(log_2(|H|)\\)"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-05.html#vcdim",
    "href": "posts/understanding-machine-learning/UML-05.html#vcdim",
    "title": "Understanding Machine Learning 05",
    "section": "",
    "text": "here we go to one of the famous theories, the VC dimension\nbefore going a little deeper, we will have a look at the motivation\n\n\nfirst, finite is not a sufficient and necessary condition of PAC learnability. exercise 3.3 is a simple example. Moreover, in the last post (No-Free-Lunch theorem), we have seen H that contains all possible functions is not PAC learnable. When we rethink the proof, we may notice that the construction of set \\(C\\) is the key point. Since we are considering all possible functions, the error of different f’s can cancel, resulting in a large error.\nborrow the idea, if we can find a subset \\(C\\) of domain \\(\\mathcal{X}\\), and if H contains all the functions when taking \\(C\\) as the domain, then it will cause a considerable risk using the same proof\nfurther, if such kind of \\(C\\) is infinitely large, then \\(H\\) is not learnable\nthe thoughts above give us the basic idea of how the VC dimension comes\n\n\n\n\nDef. restriction of H to C\nhere, \\(\\mathcal{C}=\\{c_1,c_2,\\dots,c_m\\}\\subseteq\\mathcal{X}\\)\nand \\(\\mathcal{H}_C=\\{h(c_1),\\dots,h(c_m)\\}\\)\n\nDef. Shattering\nH shatters C \\(\\iff\\) \\(|H_C|=2^{|C|}\\)\n\nDef. VC-dimension\nthe VC-dimension of H \\(\\coloneq\\max_C\\{|H_C|:\\text{H shatters C}\\}\\)\n\na simple method to show VCdim=d we need to show that\n\n\\(\\exists C\\) of size d that is shattered by H\nevery C of size d+1 is not shattered by H\n\n\nsince \\(2^{|VCdim(H)|}\\le |H|\\), we have a loose upper bound of VC dim which is \\(log_2(|H|)\\)"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-05.html#fundamental-theorem-of-pac-learning",
    "href": "posts/understanding-machine-learning/UML-05.html#fundamental-theorem-of-pac-learning",
    "title": "Understanding Machine Learning 05",
    "section": "fundamental theorem of PAC learning",
    "text": "fundamental theorem of PAC learning\nthe followings are eq\n\nuniform convergence\nPAC learnable on every ERM learner\nagnostic PAC learnable on every ERM learner\nfinite VC dimension\n\n\nfrom 4. to 1. is non-trivial. here we will go deeper into that\nwe need to find \\(m_H^U\\) s.t. for any S that \\(|S|\\ge m_H^U\\) is \\(\\frac{\\epsilon}{2}\\)-representative (i.e. \\(L_D(h)-L_S(h)|\\le \\frac{\\epsilon}{2}\\))\nintuitively, if \\(m\\) is larger than \\(d\\), where \\(d\\) is the VC dimension, \\(H_C\\) will only take small part of \\(2^C\\) (in fact that is polynomial large w.r.t. \\(|C|\\)), the estimation error could be bounded by \\(o(m)\\)\n\nSauer’s Lemma\n\nDef. Growth Function\n\\[\\tau_H(m)=\\max_{C\\subset \\mathcal{X}:|C|=m}|H_C|.\\]\n\naccording to Sauer’s lemma, \\(\\tau_H(m)\\le \\sum_{i=0}^d\\tbinom{n}{i}\\), if \\(m\\gt d+1\\), we have a looser but neat form \\(\\tau_H(m)\\ge (em/d)^d\\)\n\nproof\nbasic idea\nwe prove a stronger claim, \\(\\forall C=\\{c_1,\\dots,c_m\\}\\)\nwe have \\(\\forall H,\\ |H_C|\\le |\\{B\\subseteq C: \\text{H shatters B}\\}|\\)\ninduction on m\nwhen m=1, both sides are equal\nwhen m=k+1, suppose the claim holds for \\(m\\le k\\).\nto use the claim, we need to split \\(C\\) as \\(\\{c_1\\}\\) and ${c_1,, c_m} which is denoted as \\(C'\\)\nwe need to find such \\(H'\\) that can naturally convert from \\(C'\\) to \\(C\\) but still holds the shattering property\nnote:\n\\[\nH_C=H_{C'}\\oplus H'_{C'}\n\\]\nwhere \\(H'_{C'}=\\{\\exists f(c_1)=1\\land g(c_1)=0\\land f_{C'}=g_{C'}, \\text{ where }f,g\\in H\\}\\), \\(\\oplus\\) means direct sum (\\(H_{C'}\\cap H'_{C'}=\\emptyset\\))\n\nif \\(f_{C'}\\) and \\(g_{C'}\\) are exactly the same, they represent the same function in \\(H_{C'}\\), and hence only count once in \\(H_{C'}\\) which should be treated separatedly in \\(H_C\\).\n\nso we have that\n\\[\n\\begin{aligned}\n    |H_C|&=|H_{C'}|+|H'_{C'}|\\\\\n    &\\le |\\{B\\subseteq C':\\text{H shatters B}\\}|+|\\{B\\subseteq C':\\text{H' shatters B}\\}|\n\\end{aligned}\n\\]\nnote that \\(H'\\) shatters B \\(\\iff\\) H shatters \\(\\{c_1\\}+B\\)\nso RHS \\(\\le |\\{B\\subseteq C:\\text{H shatters B}\\}|\\) \\(\\blacksquare\\)\n\n\n\nuniform convergence\nwe will give the upper bound without proof :(\nfor every \\(\\delta\\), with prob \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\)\n\\[\n|L_D(h)-L_S(h)|\\le \\frac{4+\\sqrt{log(\\tau_H(2m))}}{\\delta \\sqrt{2m}}\n\\]\nRHS \\(\\in o(m)\\)\n\nI’ll add the proof when I master this math skill :("
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-05.html#exercise",
    "href": "posts/understanding-machine-learning/UML-05.html#exercise",
    "title": "Understanding Machine Learning 05",
    "section": "exercise",
    "text": "exercise\n\n6.1. monotonicity of VC dim\n6.2. finite X, \\(k\\lt |\\mathcal{X}|\\), compute the VC dim\n\n\\(H_{=k}^\\mathcal{X}=\\{h\\in \\{0,1\\}^\\mathcal{X}:|x:h(x)=1|=k\\}\\). VC dim=\\(\\min\\{k,|\\mathcal{X}|-k\\}\\), otherwise you can’t assign all one (zero) to these instances\n\\(H_{\\text{at most k}}^\\mathcal{X}=\\{|x:h(x)=1|\\le k \\text{ or }|x:h(x)=0|\\le k\\}\\). VC dim=k.\n\n6.3. parity function \\(h_I\\) (h computes the parity of bits at \\(I\\) ). finte H, \\(d\\le n\\), and easy to construct such \\(C\\) that \\(|C|=n\\)\n6.4. skip\n6.5. The VC dim of axis-aligned rectangles in d-dim is 2d. Since we need 2d points to construct a rectangle that assigns all points as one if there are 2d+1 points, one of them must stay inside the box (or lie on the border with no points in the box). With that point assigned as zero, others assigned as one, no function will satisfy\n6.6. VC-dimension of Boolean conjuntions \\(H_{con}^d\\): \\(f(x)=x_{i_1}\\land \\dots \\land x_{i_k}\\)\n\nprove \\(|H_{con}^d|\\le 3^d + 1\\). each \\(x_i\\) has three states, not chosen, origin \\(x_i\\), inverse \\(\\bar{x}_i\\), so should be \\(= 3^d\\) ??\nprove \\(VCdim(H)\\le d log 3\\). \\(VDdim\\le log(|H|)=dlog3\\)\nshow that \\(H_{con}\\) shatters \\(\\{e_i:i\\le d\\}\\), seems easy\nshow that \\(VCdim(H)\\le d\\). if \\(d+1\\), consider hypothesis \\(h_i(c_j) = \\begin{cases}\n   0 &\\text{if } i=j \\\\\n   1 &\\text{otherwise}\n\\end{cases}\\) .that means each \\(c_i\\) has at least one bit that is different from others, which is a contradiction\n\\(H_{mcond}^d\\) which do not contain negations, empty conjunction is considered as all positive, the vc dim of \\(H_{mcond}^d\\) with all negative h =d. first \\(VCdim(H_{mcond})\\le d\\). consider \\(x_i\\) is all one but zero at index i, \\(i\\le d\\)\n\n6.7. skip\n6.8. show vcdim of \\(H=\\{x\\mapsto \\lceil sin(\\theta x) \\rceil: \\theta \\in \\mathbb{R}\\}\\) is infinity.\n\nhint: if \\(0.x_1x_2x_3\\dots\\) is the binary expansion of \\(x\\in (0,1)\\), then for any natual number m, \\(\\lceil sin(2^m\\pi x) \\rceil =(1-x_m)\\), provided that \\(\\exist k\\ge m\\) s.t. \\(x_k=1\\).\nwith the hint, that is easy. Just construct a huge matrix with each row representing a binary expansion of \\(x_i\\) and the columns running through all possible combinations.\n\n6.9. skip\n6.10. skip\n6.11. VC of union. \\(H_1,\\dots,H_r\\).\n6.12. Dudley classes.\n\n\\(VCdim(POS(\\mathcal{F}+g))=VCdim(POS(\\mathcal{F}))\\). “\\(\\mathbb{R}ightarrow\\)”, \\((f_1+g)-(f_2+g)\\).\n\\(VCdim(POS(\\mathcal{F}))=\\dim(\\mathcal{F})\\). half space, full rank, bla bla bla\nexamples of Dudley classes\n\n\nbtw, Dudley class seems to be a fascinating and important topic"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-01.html",
    "href": "posts/understanding-machine-learning/UML-01.html",
    "title": "Understanding Machine Learning 01",
    "section": "",
    "text": "domain set. a set of instances \\(\\mathcal{X}\\)\nlabel set. \\(\\mathcal{Y}\\)\ntraining data. finite sequence \\(\\mathcal{S}\\) in \\(\\mathcal{X}\\times \\mathcal{Y}\\)\nlearner. output a rule, \\(h:\\mathcal{X}\\rightarrow\\mathcal{Y}\\). learning algorithm \\(\\mathcal{A(S)}\\)\ndata-generation model. ideally, we assume (for sim) there exists a \"correct\" labeling funciton, \\(f\\). and \\(\\mathcal{S}\\) is generated under an unknown distrib \\(\\mathcal{D}\\), then labeling it using \\(f\\).\nmeasurement. actually generalization error (risk or true error of \\(f\\))\n\n\\[\nL_{\\mathcal{D},f}(h):=\\mathbb{P}_{x\\sim D}[h(x)\\neq f(x)]:=\\mathcal{D}(\\{x:h(x)\\neq f(x)\\})\n\\]\nwhere \\(\\mathcal{D}\\) desc the prob of the event of observation.\n\\(\\mathcal{D}(A):=\\mathbb{P}_{x\\sim D}[\\pi(x)]\\), where \\(\\pi\\) is the char func of whether it was observed. \\(A={x\\in \\mathcal{X}:\\pi(x)=1}\\)"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-01.html#formal-def",
    "href": "posts/understanding-machine-learning/UML-01.html#formal-def",
    "title": "Understanding Machine Learning 01",
    "section": "",
    "text": "domain set. a set of instances \\(\\mathcal{X}\\)\nlabel set. \\(\\mathcal{Y}\\)\ntraining data. finite sequence \\(\\mathcal{S}\\) in \\(\\mathcal{X}\\times \\mathcal{Y}\\)\nlearner. output a rule, \\(h:\\mathcal{X}\\rightarrow\\mathcal{Y}\\). learning algorithm \\(\\mathcal{A(S)}\\)\ndata-generation model. ideally, we assume (for sim) there exists a \"correct\" labeling funciton, \\(f\\). and \\(\\mathcal{S}\\) is generated under an unknown distrib \\(\\mathcal{D}\\), then labeling it using \\(f\\).\nmeasurement. actually generalization error (risk or true error of \\(f\\))\n\n\\[\nL_{\\mathcal{D},f}(h):=\\mathbb{P}_{x\\sim D}[h(x)\\neq f(x)]:=\\mathcal{D}(\\{x:h(x)\\neq f(x)\\})\n\\]\nwhere \\(\\mathcal{D}\\) desc the prob of the event of observation.\n\\(\\mathcal{D}(A):=\\mathbb{P}_{x\\sim D}[\\pi(x)]\\), where \\(\\pi\\) is the char func of whether it was observed. \\(A={x\\in \\mathcal{X}:\\pi(x)=1}\\)"
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-01.html#erm-empirical-risk-minimization",
    "href": "posts/understanding-machine-learning/UML-01.html#erm-empirical-risk-minimization",
    "title": "Understanding Machine Learning 01",
    "section": "ERM (empirical risk minimization)",
    "text": "ERM (empirical risk minimization)\nuse training loss to approx generalization loss.\n\noverfitting\nwe may obtain a bunch of funcs just by ERM. so we need an inductive bias to set a preference on a certain funcs.\nwe choose the hypothesis space H before seeing the data. restric our search space of the ERM, otherwise we got a trivial useless solution.\nbefore seeing the data \\(\\rightarrow\\) should be based on some prior knowledge."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-01.html#h",
    "href": "posts/understanding-machine-learning/UML-01.html#h",
    "title": "Understanding Machine Learning 01",
    "section": "H",
    "text": "H\nexamples of H\n\nfinite H space\n\\(\\mathcal{H}\\) will not overfit provided a sufficiently large training set.\nnote: the class of axix-aligned rectangles could be finite if we consider it on a computer. (discrete repr of real numbers)\n\\(h_S\\in argmin_{h\\in H}L_s(h)\\)\nsince S are randomly chosen, so \\(h_S,L_{D,f}\\) are actually random vars.\n\n\na few assumptions\na few assumptions on the PAC learnability\n\ndef the realizability assumption\nthere exists \\(h^\\star\\in\\mathcal{H}\\) s.t. \\(L_{D,f}(h^\\star)=0\\)\nfurther, we have\n\\(\\rightarrow L_S(h^\\star)=0 \\text{ with prob 1 over the S }\\rightarrow L_S(h_S)=0\\)\nwe are interested in \\(L_{D,f}(h_S)\\)\n\n\nconfidence param\nwe address a prob \\(\\delta\\) of getting a very nonrepresentative training set (e.g all lie in class A). and \\((1-\\delta)\\) is the confidence of our prediction.\n\n\naccuracy param\n\\(\\epsilon\\)\nwe call \\(L_{D,f}(h_S)\\ge \\epsilon\\) as a failure of the learner, otherwise approx correct predictor.\nSo we're interested in the upper bound of prob to sample S that leads to the learner’s failure.\nupper bound of\n\\[\nD^m\\{S|_x:L_{D,f}(h_S)\\gt \\epsilon\\}\n\\]\nlet \\(H_B\\) be the set of bad hypotheses\n\\[\n\\{h\\in H: L_{D,f}\\gt \\epsilon\\}\n\\]\nlet M be the set of the misleading training set\n\\[\n\\{S|_x:\\exists h\\in H_B, L_S(h)=0\\}\n\\]\nwhere \\(S|_x\\) is the instances of tr set\ndue to real.. assumption, only M will cause failure.\nso only a subset of S from M will cause \\(h_S\\) to fail.\n\\[\n\\begin{align}\n&D^m\\{S|_x:L_{D,f}(h_S)\\gt \\epsilon\\} \\\\\n\\le& \\sum_{h\\in H_B}D^m\\{S|_x:L_S(h)=0\\}\\\\\n=&\\sum_{h\\in H_B}\\prod D\\{x_i:h(x_i)=f(x_i)\\}\n\\end{align}\n\\]\nhere, the countability of \\(\\mathcal{H}\\) is used, and I think if we can control the order of \\(|\\mathcal{H}|\\) and with more careful scaling (with more assumption or knowledge about the h's, like \\(D^m\\{S|_x:L_S(h)=0\\}\\) can be approx related to h) then we could have the inf conclusion, though maybe not that interesting, and there are other ways on it.\nand\n\\[\nD\\{x_i:h(x_i)=f(x_i)\\}=1-L_{D,f}(h)\\le 1-\\epsilon\n\\]\nso using a series of loose relaxation, we have\n\\[\nD^m\\{S|_x:L_{D,f}(h_S)\\}\\le |H_B|e^{-\\epsilon m}\\le |H|e^{-\\epsilon m}\n\\]\nfinite is used here\nLHS is \\(\\delta\\)\nNote sometimes m should be really large to ensure with at least \\(1-\\delta\\) confidence over the choice of S, every ERM hypothesis, \\(h_S\\) is approx correct."
  },
  {
    "objectID": "posts/understanding-machine-learning/UML-01.html#small-corollary",
    "href": "posts/understanding-machine-learning/UML-01.html#small-corollary",
    "title": "Understanding Machine Learning 01",
    "section": "small corollary",
    "text": "small corollary\nwhen hypothesis space is finite, then we can immediately have an upper bound for \\(m_{\\mathcal{H}}\\)\n\\[\nm_{\\mathcal{H}}(\\epsilon,\\delta)\\le \\left \\lceil \\frac{log\\left(|\\mathcal{H}|/\\delta\\right)}{\\epsilon} \\right \\rceil\n\\]"
  },
  {
    "objectID": "posts/understanding-machine-learning/uml-06.html",
    "href": "posts/understanding-machine-learning/uml-06.html",
    "title": "Understanding Machine Learning 06",
    "section": "",
    "text": "we will summarize different kinds of defs of learnability first"
  },
  {
    "objectID": "posts/understanding-machine-learning/uml-06.html#learnability",
    "href": "posts/understanding-machine-learning/uml-06.html#learnability",
    "title": "Understanding Machine Learning 06",
    "section": "learnability",
    "text": "learnability\n\nPAC learnability\nH is PAC learnable if the realizability assumption holds and\n\\(\\forall \\epsilon,\\delta\\gt 0\\), there exists a learner A and \\(m_H(\\epsilon,\\delta)\\) s.t. if \\(m\\ge m_H\\)\nfor any D, with probability greater than \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\)\n\\[\nL_D(A(S))\\le \\epsilon\n\\]\n\n\nagnostic PAC learnability\nH is agnostic PAC learnable if\n\\(\\forall \\epsilon,\\delta\\gt 0\\), there exists a learner A and \\(m_H(\\epsilon,\\delta)\\) s.t. if \\(m\\ge m_H\\)\nfor any D, with probability greater than \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\)\n\\[\nL_D(A(S))\\le \\min_{h\\in H}\\{L_D(h)\\}+\\epsilon\n\\]\n\n\nuniform convergence property\nH enjoys the uniform convergence property if\n\\(\\forall \\epsilon,\\delta \\gt 0\\), there exists \\(m_H^{UC}(\\epsilon, \\delta)\\) s.t. if \\(m\\ge m_H^{UC}\\)\nfor any D, with probability greater than \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\), \\(\\forall h\\in H\\)\n\\[\n|L_S(h) - L_D(h)|\\le\\epsilon\n\\]\nthese defination of learnibility are equal according to the fundamental theory\n\nhere we have another def which has different power with the above"
  },
  {
    "objectID": "posts/understanding-machine-learning/uml-06.html#nonuniform-learnability",
    "href": "posts/understanding-machine-learning/uml-06.html#nonuniform-learnability",
    "title": "Understanding Machine Learning 06",
    "section": "nonuniform learnability",
    "text": "nonuniform learnability\nwe allow \\(m_H\\) to be non-uniform over h\nH is nonuniform learnable if\n\\(\\forall \\epsilon,\\delta\\gt 0\\) there exists a learner A and \\(m_H^{NU}(\\epsilon,\\delta,h)\\), s.t. for all \\(h\\in H\\), if \\(m\\ge m_H^{NU}(\\epsilon,\\delta,h)\\)\nfor any D, with probability greater than \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\)\n\\[\nL_D(A(S))\\le L_D(h)+\\epsilon\n\\]\nnote when m is decided, and it is that makes non-uniform learnability weaker than PAC\n\nproperty\nH is nonuniform learnable iff H can be expressed as a union of countable \\(H_i\\) with uniform convergence property\nwe can easily construct H that is nonuniform learnable but not PAC learnable which means PAC learnability is stronger\n\n\ngeneric learner\nERM is a fittable learer for PAC learnability\nSRM (structural risk minimization) is a fittable learner for NU learnability\nSRM requires us to provide more prior knowledge on the priority (weights) of \\(H_i\\)’s.\ndef \\(\\epsilon_n(m,\\delta)=\\min\\{\\epsilon\\in (0,1):m_{H_n}^{UC}(\\epsilon,\\delta)\\le m\\}\\) which means the minimum est error we can get with m samples\nso given m samples\n\\[\n\\forall h\\in H_n,|L_D(h)-L_S(h)|\\le \\epsilon_n(m,\\delta)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nnote m here can be varied (I’m not so sure about this) or large enough (s.t. \\(\\forall n,\\epsilon_n(m,\\delta)\\le \\epsilon\\)) during training\n\n\nwhen we put this on a larger range (\\(H_n\\rightarrow H\\)) directly, we can’t garantee we satisfy the \\(\\delta\\) constraint, since each one has relatively low confidence \\(1-\\delta\\). So we have to split the confidence to each \\(H_i\\), that is providing weights \\(\\sum_{n\\in\\mathbb{N}}w(n)\\le 1\\) on each \\(\\delta\\) (use union bound inequality to merge it back)\nto put it formally\ngiven \\(H=\\cup_{n\\in\\mathbb{N}}H_n\\) and \\(\\sum_{n\\in\\mathbb{N}}w(n)\\le 1\\), where \\(H_i\\) satisfy UC property, then\nwith probatility of at least \\(1-\\delta\\) over the choice \\(S\\sim D^m\\)\nfor any \\(n\\in\\mathbb{N}\\) and \\(h\\in H_n\\)\n\\[\n|L_D(h)-L_S(h)|\\le \\epsilon_n(m,w(n)\\cdot \\delta)\n\\]\nwhich implies for \\(\\forall h\\in H\\)\n\\[\nL_D(h)\\le L_S(h)+\\min_{n:h\\in H_n}\\epsilon_n(m,w(n)\\cdot\\delta)\n\\]\nif we make it simpler (but looser), let \\(n(h)=min\\{n:h\\in H_n\\}\\)\n\\[\nL_D(h)\\le L_S(h)+\\epsilon_n(m,w(n(h))\\cdot\\delta)\n\\]\nSO, SRM is to minimizing the RHS\nwe can proof that \\(L_D(A(S))\\le L_D(h)+\\epsilon\\) with p at least \\(1-\\delta\\) over the choice of S (if \\(m\\ge m_{H_{n(h)}}^{UC}(\\epsilon/2,w(n(h))\\cdot \\delta)\\))\n\nin fact, any converged sumations should be ok for w, like \\(w(n)=\\frac{6}{n^2\\pi^2}\\)\nintuitively, \\(H_n\\) with larger \\(w(n)\\) will need less samples since it is required for less confidence, we actually focus on some hypothesis classes instead of treat all \\(H_n\\) evenly.\nsecond, if \\(h_1\\) and \\(h_2\\) has the same empirical risk, we will prefer the one with higher weight if using SRM\nseems familiar? sounds like the principle Occam’s razor\n\n\ndescription length\nwe now consider a countable \\(H\\). it can be expressed as a union of singleton class \\(H_i=\\{h_i\\}\\) and for each \\(H_i\\), \\(m_{H_i}^{UC}(\\epsilon,\\delta)= \\left\\lceil\\frac{log(2/\\delta)}{2\\epsilon^2}\\right\\rceil\\)\nthen \\(e_n(m,w(n(h))\\cdot \\delta)= \\sqrt{\\frac{-logw(n(h)) +log(2/\\delta)}{2m}}\\)\ndef description language \\(\\{0,1\\}^\\star\\)\nwe assign each \\(H_i\\) with a description \\(d(h)\\) and denote \\(|h|=|d(h)|\\)\n\n\n\n\n\n\nNote\n\n\n\nif S is a prefix-free set of strings, then\n\\[\n\\sum_{\\sigma\\in S}\\frac{1}{2^{|\\sigma|}}\\le 1\n\\]\n\n\nso \\(w(h)=\\frac{1}{2^{|h|}}\\) is a legal weight function\nand the hypothesis with smaller description length is preferable if they have the same risk\nthat’s the principle of Occam’s razor"
  },
  {
    "objectID": "posts/understanding-machine-learning/uml-06.html#consistency",
    "href": "posts/understanding-machine-learning/uml-06.html#consistency",
    "title": "Understanding Machine Learning 06",
    "section": "consistency",
    "text": "consistency\n\n\n\n\n\n\nNote\n\n\n\nif we let \\(m_H\\) further be dependent on the distribution, we have the def of consistency\n\n\na learner A is consistency with respect to H and P where P is the set of possible distribution D’s, if\n\\(\\forall \\epsilon,\\delta\\gt 0\\) there exists a learner A and \\(m_H^{NU}(\\epsilon,\\delta,h,D)\\), s.t. for all \\(h\\in H\\) and \\(D\\in P\\), if \\(m\\ge m_H^{NU}(\\epsilon,\\delta,h,D)\\)\nwith probability greater than \\(1-\\delta\\) over the choice of \\(S\\sim D^m\\)\n\\[\nL_D(A(S))\\le L_D(h)+\\epsilon\n\\]\n\n\n\n\n\n\nNote\n\n\n\nif P is the set of all distributions, then A is universally consistent with respect to H\n\n\nthis def of learnability is even weaker than NU\nthe algorithm Memorize is universally consistent which will be overfit in the context of PAC learnability!!! (for every countable domain and finite label set w.r.t. zero-one loss)\ndef Memorize(x)\n    return y if (x,y) in S else 0 # any default value \n\nwhy different ability?\nnote when we determine the \\(m\\)"
  },
  {
    "objectID": "posts/understanding-machine-learning/uml-06.html#exercise",
    "href": "posts/understanding-machine-learning/uml-06.html#exercise",
    "title": "Understanding Machine Learning 06",
    "section": "exercise",
    "text": "exercise\n\n7.5. H that contains all functions is not nonuniform learnable\n\nconclusion: \\(H=\\cup_{n\\in\\mathbb{N}}H_n\\), if H shatters an infinite set, the some \\(H_n\\) has infinite VC dim"
  },
  {
    "objectID": "posts/calculus/calculus-01.html",
    "href": "posts/calculus/calculus-01.html",
    "title": "calculus review 01",
    "section": "",
    "text": "linear transformations\nmeasure of matrices: \\(\\left \\rVert A\\right \\lVert_F^2\\)\ntriangle inq in matrices: \\(\\rVert AB \\lVert\\le \\rVert A\\lVert\\rVert B\\lVert\\)\nthe neighborhood of \\(x\\), exist an open ball init\nclosure \\(\\bar{A}\\), the smallest close-set that contains A\ninterior \\(\\mathring{A}\\), the largest open set that A contains\nthe boundary of subset, \\(\\partial A\\)\n\nconvergence of a sequence, in terms of coordinates\nlimits of multivariable functions: continuity is preserved under dot product operation\ncontinuity: the preimage of a neighborhood of \\(f(x)\\) is also a neighborhood of x\nuniform continuity: linear transformations are uniform continuity\nconvergence of the sum of series (vectors): absolute(norm in vector cases) convergence implies convergence\ncomplex exponentials\n\ncomplex exponential series converges: \\(e^z=1+z+\\frac{z^2}{2!}+\\dots=\\sum_{k=0}^\\infty \\frac{z^k}{k!}\\), since the absolute series converges\n\neuler formular: \\(e^{it}=cost+isint\\)\ngeometric series of matrices:\n\n\\(S=I+A+A^2+\\dots\\) converges to \\((1-A)^{-1}\\) if \\(\\lVert A \\rVert \\lt 1\\)\nthe set of invertible n by n matrices is open\n\nbounded: subset \\(X\\subset \\mathbb{R}^n\\) is bounded if it is contained in some ball centered at the origin\ncompact: nonempty subset \\(C\\subset \\mathbb{R}^n\\) is compact if it is closed and bounded"
  },
  {
    "objectID": "posts/calculus/calculus-01.html#basic",
    "href": "posts/calculus/calculus-01.html#basic",
    "title": "calculus review 01",
    "section": "",
    "text": "linear transformations\nmeasure of matrices: \\(\\left \\rVert A\\right \\lVert_F^2\\)\ntriangle inq in matrices: \\(\\rVert AB \\lVert\\le \\rVert A\\lVert\\rVert B\\lVert\\)\nthe neighborhood of \\(x\\), exist an open ball init\nclosure \\(\\bar{A}\\), the smallest close-set that contains A\ninterior \\(\\mathring{A}\\), the largest open set that A contains\nthe boundary of subset, \\(\\partial A\\)\n\nconvergence of a sequence, in terms of coordinates\nlimits of multivariable functions: continuity is preserved under dot product operation\ncontinuity: the preimage of a neighborhood of \\(f(x)\\) is also a neighborhood of x\nuniform continuity: linear transformations are uniform continuity\nconvergence of the sum of series (vectors): absolute(norm in vector cases) convergence implies convergence\ncomplex exponentials\n\ncomplex exponential series converges: \\(e^z=1+z+\\frac{z^2}{2!}+\\dots=\\sum_{k=0}^\\infty \\frac{z^k}{k!}\\), since the absolute series converges\n\neuler formular: \\(e^{it}=cost+isint\\)\ngeometric series of matrices:\n\n\\(S=I+A+A^2+\\dots\\) converges to \\((1-A)^{-1}\\) if \\(\\lVert A \\rVert \\lt 1\\)\nthe set of invertible n by n matrices is open\n\nbounded: subset \\(X\\subset \\mathbb{R}^n\\) is bounded if it is contained in some ball centered at the origin\ncompact: nonempty subset \\(C\\subset \\mathbb{R}^n\\) is compact if it is closed and bounded"
  },
  {
    "objectID": "posts/calculus/calculus-01.html#important-theorem",
    "href": "posts/calculus/calculus-01.html#important-theorem",
    "title": "calculus review 01",
    "section": "important theorem",
    "text": "important theorem\n\nBolzano-Weierstrass theorem: a compact set C contains a seq, then that seq has a convergent sub seq whose limit is in C\na continuous function on a compact set achieves its minimum and maximum\nthe mean value theorem\ncontinuity on a compact set is uniform continuity\nthe fundamental theorem of algebra"
  },
  {
    "objectID": "posts/calculus/calculus-01.html#differentiable",
    "href": "posts/calculus/calculus-01.html#differentiable",
    "title": "calculus review 01",
    "section": "differentiable",
    "text": "differentiable\n\ndef\ndifferentiable means \\(f\\) can be well approximated at \\(x=a\\) by a linear transformation\nlet \\(f:\\mathcal{U}\\to\\mathbb{R}^m\\) where \\(\\mathcal{U}\\) is a open subset of \\(\\mathbb{R}^n\\)\n\\(D_if(a)\\) means the partial derivative on the i-th value. It is an m by 1 vertical vector\nwe can treat it like the mapped element from \\(e_i\\)\n\\(Df(a)\\) is an m by n matrix where we stack \\(D_i\\)’s in a row\nthe precise def of the derivative is as below:\n\\(Df(a)\\) is a linear transformation from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\), s.t.\n\\[\n\\lim_{h\\to 0}\\frac{1}{|h|}\\left( (f(a+h)-f(a)) - [Df(a)]h\\right )=0\n\\]\n\n\nJacobian matrix\nJacobian matrix now fits this definition and don’t need for any transpose.\nnote the existence of Jacobian matrix does not mean differentiable, except that we let \\(f\\) to be continuously differentiable. I won’t present any examples of why and how. We just need to focus on the \\(C^1\\) functions from now on :\n\n\nfor some cases where the domain is not the subspace of Euclidiean space, we may need to use the definition of derivative instead of the Jacobian matrix.\ne.g. 1\n\\(\\mathcal{S}:Mat(n,n)\\to Mat(n,n)\\) given by \\(S(A)=A^2\\)\n\\[[\\mathbf{D}S(A)]H=AH+HA\\]\ne.g. 2\n\\(f(A)=A^{-1}\\) defined on invertible n by n matrices\n\\[[\\mathbf{D}f(A)]H=-A^{-1}HA^{-1}\\]\n\n\n\nabout gradient\n\\[\ngrad\\ f(a)=\\vec{\\nabla} f(a)=[D_1f(a),\\dots, D_nf(a)]^\\intercal\n\\]\nwhere \\(f:\\mathbb{R}^n\\to \\mathbb{R}\\)\nFrom my POV, gradient is the solution of the fastest increasing direction at some point \\(a\\) and it happens to be the (transpose of) derivative. note the transpose has its meaning, it makes the grad lying in the domain.\nfurthermore, from how we get the solution, we should have an inner-product defined on the domain space, which is not the case in the def of derivative.\n\n\ndirectional derivative\ndirectional derivative of \\(f\\) at \\(a\\) in the derection \\(\\vec{v}\\)\n\\[\n[Df(a)]\\vec{v}\n\\]\nthis is how linear transformation works.\n\n\nrules\n\nconstant function: 0\nlinear function: itself\n\\(\\mathbf{f}=(f_1,\\dots,f_m)^\\intercal\\) then\n\\[[Df(a)]\\vec{v}=\\left[[Df_1(a)]\\vec{v},\\cdots,[Df_m(a)]\\vec{v}\\right]^\\intercal\\]\n\\([D(f+g)(a)]=[Df(a)]+[Dg(a)]\\)\n\\(f:U\\to \\mathbb{R}\\) and \\(\\mathbf{g}:U\\to \\mathbb{R}^m\\)\n\\[\n[D(f\\mathbf{g})]\\vec{v}=f(a) [D\\mathbf{g}(a)]\\vec{v}+([Df(a)]\\vec{v})\\mathbf{g}(a)\n\\]\n\\[\\left[D\\left(\\frac{\\mathbf{g}}{f}\\right)(a)\\right]\\vec{v}=\\frac{[D\\mathbf{g}(a)]\\vec{v}}{f(a)}-\\frac{([Df(a)]\\vec{v})g(a)}{f^2(a)}\\]\ndot product \\(\\mathbf{f}:U\\to \\mathbb{R}^m\\)\n\\[\n[D(\\mathbf{f}\\cdot\\mathbf{g})]\\vec{v}=\\mathbf{f}(a)\\cdot[D\\mathbf{g}(a)]\\vec{v}+([D\\mathbf{f}(a)]\\vec{v})\\cdot\\mathbf{g}(a)\n\\]\nchain rule\n\\[[D(f\\circ g)(a)]=[Df(g(a))][Dg(a)]\\]\n\n\nref\n\nVector Calculus, Linear Algebra, and Differential Forms: A Unified Approach"
  },
  {
    "objectID": "posts/calculus/calculus-03.html",
    "href": "posts/calculus/calculus-03.html",
    "title": "calculus review 03",
    "section": "",
    "text": "New stuff (to me)\n\n\n\n\n\n\n\n\nNote\n\n\n\nmanifold: a subset \\(M\\subset \\mathbb{R}^n\\) is a smooth \\(k\\)-dimensional manifold\nif locally it is the graph of a \\(C^1\\) mapping \\(f\\) expressing \\(n-k\\) variables as functions of the other \\(k\\) variables\n\n\nThe definition seems highly related to the implicit function theorem\nTherefore, we can quickly catch the spirit below\nlet \\(\\mathbf{F}:U\\rightarrow \\mathbb{R}^{n-k}\\) be a \\(C^1\\) mapping, where \\(U\\subset\\mathbb{R}^n\\).\n\n\n\n\n\n\nNote\n\n\n\n\nSome subset \\(M\\) of the domain \\(U\\) is a \\(k\\)-dimensional manifold if \\(\\mathbf{F}(z)=0\\) and \\([D\\mathbf{F}(z)]\\) is onto for every \\(z\\in M\\).\n(converse) if \\(M\\) is a smooth \\(k\\)-dimensional manifold, then for every \\(z\\in M\\), there exists \\(\\mathbf{F}\\) s.t., \\([D\\mathbf{F}(z)]\\) is onto and \\(\\mathbf{F}(y)=0\\) with a neighborhood of \\(z\\) as the domain\n\n\n\n\\(\\star\\) it says we can virtually claim a manifold by \\(\\mathbf{F}(z)=0\\)\nintuitively, the definition of manifold should not depend on the coordinates\n\n\n\n\n\n\nNote\n\n\n\n\\(k\\)-dimensional manifold \\(M\\subset\\mathbb{R}^m\\), \\(f\\) is a mapping with some properties 1\nthen \\(f^{-1}(M)\\) is a submanifold of \\(\\mathbb{R}^n\\) of dimension \\(k+n-m\\)\n\n\n1  \\(f:U\\rightarrow\\mathbb{R}^m\\) where \\(U\\) is an open subset of \\(\\mathbb{R}^n\\) and \\([Df(x)]\\) is surjective at \\(\\forall x\\in f^{-1}(M)\\)as a corollary, manifolds are independent of coordinates if \\(f\\) is an affine transformation\n\n\n\nparametrization is useful for analysing manifolds since taking a manifolds as domain directly is rather cumbersome\n\n\n\n\n\n\nNote\n\n\n\na parametrization of a \\(k\\)-dimensional manifold \\(M\\subset\\mathbb{R}^n\\) is a mapping \\(\\gamma:U\\subset\\mathbb{R}^k\\rightarrow M\\), s.t.,\n\n\\(U\\) is open\n\\(\\gamma\\) is \\(C^1\\), one to one, and onto \\(M\\)\n\\([D\\gamma(u)]\\) is one to one for every \\(u\\in U\\)\n\n\n\n\nas a comparison, linear algebra and differential calculus have mucn in common\n\nrow reduction \\(\\leftrightarrow\\) newton’s method\nkernels \\(\\leftrightarrow\\) defining manifolds by equations ( e.g., \\(f(x)=0\\) )\nimages \\(\\leftrightarrow\\) defining manifolds by a parametrization\n\n\n\n\n\ntangent space is similar to the linear approximation of a function \\(f\\), but it is used on a manifold.\n\n(derivative) replace a function \\(f\\) locally by a linear map\n(tangent space) replace a manifold locally by a linear space\n\nfor a manifold \\(M=\\left\\{\\left(\\begin{matrix} x\\\\y \\end{matrix}\\right)\\in\\mathbb{R}^n\\mid f(x)=y\\right\\}\\)\nfix \\(z_0\\in M\\).\nthe change of \\(z\\) should be approximated by a linear mapping\n\\[\ny-y_0=[Df(x_0)](x-x_0)\n\\]\nin short \\(\\Delta y=[Df(x_0)]\\Delta x\\)\n\n\n\n\n\n\nNote\n\n\n\nthe graph of \\([Df(x_0)]\\) is the tangent space, which is denoted as \\(T_{z_0}M\\)\nthe linear approximation to the graph is the graph of the linear approximation\n\n\n\n\n\nif you have an equation form \\(F(x)=0\\) of the manifold, then you are lucky.\n\n\n\n\n\n\nNote\n\n\n\nthe kernel space of the derivative of \\(F\\) is the tangent space.\n\\[\nT_{z_0}M=\\ker [DF(z_0)]\n\\]\n\n\nagain, this will certainly remind you the implicit function theorem, where we also claim the derivative of the implicit function\nhere is another approach to get the tangent space\n\n\n\n\n\n\nNote\n\n\n\nLet \\(U\\subset\\mathbb{R}^k\\) be open, and let \\(\\gamma:U\\rightarrow\\mathbb{R}^n\\) be a parametrization of manifold \\(M\\), then\n\\[\nT_{\\gamma(u)}M=\\textrm{img}[D\\gamma(u)].\n\\]\n\n\nit might look strange at first — why taking the image instead of the kernel like above.\nquick calculation:\n\\[\n[D(F\\circ\\gamma)(u)]=[DF(\\gamma(u))]\\circ[D\\gamma(u)]=[0]\n\\]\nderivative is not quite like what we think as the origin function\nhere \\(\\textrm{img}[D\\gamma(u)]\\) and \\(\\textrm{img}[DF(\\gamma(u))]\\) are orthogonal complementary subspaces\n\n\n\nTBD :)"
  },
  {
    "objectID": "posts/calculus/calculus-03.html#manifolds",
    "href": "posts/calculus/calculus-03.html#manifolds",
    "title": "calculus review 03",
    "section": "",
    "text": "New stuff (to me)\n\n\n\n\n\n\n\n\nNote\n\n\n\nmanifold: a subset \\(M\\subset \\mathbb{R}^n\\) is a smooth \\(k\\)-dimensional manifold\nif locally it is the graph of a \\(C^1\\) mapping \\(f\\) expressing \\(n-k\\) variables as functions of the other \\(k\\) variables\n\n\nThe definition seems highly related to the implicit function theorem\nTherefore, we can quickly catch the spirit below\nlet \\(\\mathbf{F}:U\\rightarrow \\mathbb{R}^{n-k}\\) be a \\(C^1\\) mapping, where \\(U\\subset\\mathbb{R}^n\\).\n\n\n\n\n\n\nNote\n\n\n\n\nSome subset \\(M\\) of the domain \\(U\\) is a \\(k\\)-dimensional manifold if \\(\\mathbf{F}(z)=0\\) and \\([D\\mathbf{F}(z)]\\) is onto for every \\(z\\in M\\).\n(converse) if \\(M\\) is a smooth \\(k\\)-dimensional manifold, then for every \\(z\\in M\\), there exists \\(\\mathbf{F}\\) s.t., \\([D\\mathbf{F}(z)]\\) is onto and \\(\\mathbf{F}(y)=0\\) with a neighborhood of \\(z\\) as the domain\n\n\n\n\\(\\star\\) it says we can virtually claim a manifold by \\(\\mathbf{F}(z)=0\\)\nintuitively, the definition of manifold should not depend on the coordinates\n\n\n\n\n\n\nNote\n\n\n\n\\(k\\)-dimensional manifold \\(M\\subset\\mathbb{R}^m\\), \\(f\\) is a mapping with some properties 1\nthen \\(f^{-1}(M)\\) is a submanifold of \\(\\mathbb{R}^n\\) of dimension \\(k+n-m\\)\n\n\n1  \\(f:U\\rightarrow\\mathbb{R}^m\\) where \\(U\\) is an open subset of \\(\\mathbb{R}^n\\) and \\([Df(x)]\\) is surjective at \\(\\forall x\\in f^{-1}(M)\\)as a corollary, manifolds are independent of coordinates if \\(f\\) is an affine transformation\n\n\n\nparametrization is useful for analysing manifolds since taking a manifolds as domain directly is rather cumbersome\n\n\n\n\n\n\nNote\n\n\n\na parametrization of a \\(k\\)-dimensional manifold \\(M\\subset\\mathbb{R}^n\\) is a mapping \\(\\gamma:U\\subset\\mathbb{R}^k\\rightarrow M\\), s.t.,\n\n\\(U\\) is open\n\\(\\gamma\\) is \\(C^1\\), one to one, and onto \\(M\\)\n\\([D\\gamma(u)]\\) is one to one for every \\(u\\in U\\)\n\n\n\n\nas a comparison, linear algebra and differential calculus have mucn in common\n\nrow reduction \\(\\leftrightarrow\\) newton’s method\nkernels \\(\\leftrightarrow\\) defining manifolds by equations ( e.g., \\(f(x)=0\\) )\nimages \\(\\leftrightarrow\\) defining manifolds by a parametrization\n\n\n\n\n\ntangent space is similar to the linear approximation of a function \\(f\\), but it is used on a manifold.\n\n(derivative) replace a function \\(f\\) locally by a linear map\n(tangent space) replace a manifold locally by a linear space\n\nfor a manifold \\(M=\\left\\{\\left(\\begin{matrix} x\\\\y \\end{matrix}\\right)\\in\\mathbb{R}^n\\mid f(x)=y\\right\\}\\)\nfix \\(z_0\\in M\\).\nthe change of \\(z\\) should be approximated by a linear mapping\n\\[\ny-y_0=[Df(x_0)](x-x_0)\n\\]\nin short \\(\\Delta y=[Df(x_0)]\\Delta x\\)\n\n\n\n\n\n\nNote\n\n\n\nthe graph of \\([Df(x_0)]\\) is the tangent space, which is denoted as \\(T_{z_0}M\\)\nthe linear approximation to the graph is the graph of the linear approximation\n\n\n\n\n\nif you have an equation form \\(F(x)=0\\) of the manifold, then you are lucky.\n\n\n\n\n\n\nNote\n\n\n\nthe kernel space of the derivative of \\(F\\) is the tangent space.\n\\[\nT_{z_0}M=\\ker [DF(z_0)]\n\\]\n\n\nagain, this will certainly remind you the implicit function theorem, where we also claim the derivative of the implicit function\nhere is another approach to get the tangent space\n\n\n\n\n\n\nNote\n\n\n\nLet \\(U\\subset\\mathbb{R}^k\\) be open, and let \\(\\gamma:U\\rightarrow\\mathbb{R}^n\\) be a parametrization of manifold \\(M\\), then\n\\[\nT_{\\gamma(u)}M=\\textrm{img}[D\\gamma(u)].\n\\]\n\n\nit might look strange at first — why taking the image instead of the kernel like above.\nquick calculation:\n\\[\n[D(F\\circ\\gamma)(u)]=[DF(\\gamma(u))]\\circ[D\\gamma(u)]=[0]\n\\]\nderivative is not quite like what we think as the origin function\nhere \\(\\textrm{img}[D\\gamma(u)]\\) and \\(\\textrm{img}[DF(\\gamma(u))]\\) are orthogonal complementary subspaces\n\n\n\nTBD :)"
  },
  {
    "objectID": "diary/inequality.html",
    "href": "diary/inequality.html",
    "title": "Inequality",
    "section": "",
    "text": "I found a great book on concentration inequalities\nConcentration inequalities: A nonasysmtotic theory of independence by Boucheron\nhope I can read this book thoroughly one day :/"
  },
  {
    "objectID": "diary/daily-reading/2024-10-05.html",
    "href": "diary/daily-reading/2024-10-05.html",
    "title": "memorial",
    "section": "",
    "text": "will be added to the awesome list of papers\n\n“Towards Understanding Grokking: An Effective Theory of Representation Learning”,“2022-05-20”,“https://arxiv.org/abs/2205.10343”,“Ziming Liu; Ouail Kitouni; Niklas Nolte; Eric J. Michaud; Max Tegmark; Mike Williams”\n\n\npaper about the benefits of very large stepsize in gradient descent / EoS:\n\n“Large Stepsize Gradient Descent for Logistic Loss: Non-Monotonicity of the Loss Improves Optimization Efficiency”,“2024-02-24”,“https://arxiv.org/abs/2402.15926”,“Jingfeng Wu; Peter L. Bartlett; Matus Telgarsky; Bin Yu”\n“Large Stepsize Gradient Descent for Non-Homogeneous Two-Layer Networks: Margin Improvement and Fast Optimization”,“2024-06-12”,“https://arxiv.org/abs/2406.08654”,“Yuhang Cai; Jingfeng Wu; Song Mei; Michael Lindsey; Peter L. Bartlett”\n“Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability”,“2023-05-19”,“https://arxiv.org/abs/2305.11788”,“Jingfeng Wu; Vladimir Braverman; Jason D. Lee”\n“On the Noisy Gradient Descent that Generalizes as SGD”,“2019-06-18”,“https://arxiv.org/abs/1906.07405”,“Jingfeng Wu; Wenqing Hu; Haoyi Xiong; Jun Huan; Vladimir Braverman; Zhanxing Zhu”\n\n\nto-read list:\n\n“Rethinking Conventional Wisdom in Machine Learning: From Generalization to Scaling”,“2024-09-23”,“https://arxiv.org/abs/2409.15156”,“Lechao Xiao”\n“Learning From Biased Soft Labels”,“2023-02-16”,“https://arxiv.org/abs/2302.08155”,“Hua Yuan; Ning Xu; Yu Shi; Xin Geng; Yong Rui”\n“Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks”,“2022-06-08”,“https://arxiv.org/abs/2206.03826”,“Jiachun Pan; Pan Zhou; Shuicheng Yan”\n“How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?”,“2023-10-12”,“https://arxiv.org/abs/2310.08391”,“Jingfeng Wu; Difan Zou; Zixiang Chen; Vladimir Braverman; Quanquan Gu; Peter L. Bartlett”\n\n\nmiscellaneous:\n\nhttps://github.com/xjdr-alt/entropix: Entropy Based Sampling and Parallel CoT Decoding\nrelated works of Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning\n\nBenign Overfitting in Two-layer Convolutional Neural Networks\nModality Competition: What Makes Joint Training of Multi-modal Network Fail in Deep Learning? (Provably)\nWhy Does Sharpness-Aware Minimization Generalize Better Than SGD?\nTowards Understanding How Momentum Improves Generalization in Deep Learning\n\nScaling Laws in Linear Regression: Compute, Parameters, and Data"
  }
]